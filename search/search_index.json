{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"Make AI Agents Collaborate:  Drag, Drop, and Orchestrate with Waldiez Get Started"},{"location":"CODE_OF_CONDUCT.html","title":"CODE OF CONDUCT","text":""},{"location":"CODE_OF_CONDUCT.html#contributor-covenant-code-of-conduct","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT.html#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT.html#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT.html#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT.html#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT.html#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at <code>development @ waldiez.io</code>. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT.html#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT.html#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT.html#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT.html#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT.html#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT.html#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"blog/index.html","title":"Index","text":""},{"location":"blog/index.html#blog","title":"Blog","text":""},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html","title":"Multi Agent Conversation and Stand up Comedy","text":"<p>This guide walks you through creating a conversational flow in JupyterLab using the Waldiez extension, where two agents, \"Joe\" and \"Cathy,\" simulate a standup comedy exchange. We will configure an OpenAI model (GPT-3.5-turbo) for this flow and observe the interaction between the agents.</p>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#using-user-input-to-start-the-conversation","title":"Using user input to start the conversation","text":"<p>In this example, we will set up a flow where the user initiates the conversation by providing an initial message. The agents, Joe and Cathy, will then respond to each other based on the user input and the previous agent's message.</p>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#open-jupyterlab-and-launch-waldiez","title":"Open JupyterLab and Launch Waldiez","text":"<ol> <li>Start JupyterLab.</li> <li>In the launcher, under the Waldiez section, select the Waldiez icon to create a new <code>.waldiez</code> file. This opens a new interface for setting up agents and configuring the flow.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#add-a-model","title":"Add a Model","text":"<ol> <li>In the Waldiez interface, click on <code>Add model</code> to add a new model configuration.</li> <li>Fill out the configuration fields:<ul> <li>Name: <code>gpt-3.5-turbo</code></li> <li>Model Type: Select <code>OpenAI</code>.</li> <li>API Key: Enter your OpenAI API key (make sure you have GPT-3.5-turbo access).</li> </ul> </li> <li>Optionally adjust Advanced Settings like Temperature and Max Tokens as per your needs.</li> <li>Click Save to add the model to your flow.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#create-agents","title":"Create Agents","text":""},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#agent-1-cathy","title":"Agent 1: Cathy","text":"<ol> <li>Under the <code>Agents</code> section, drag a new agent onto the canvas.</li> <li>Name the agent Cathy.</li> <li>Set the description to \"Cathy is a standup comedian.\"</li> <li>In the System Message field, enter: <code>Your name is Cathy and you are a standup comedian.</code></li> <li>Link the <code>gpt-3.5-turbo</code> model to Cathy by selecting it in the Models tab.</li> <li>Save the configuration.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#agent-2-joe","title":"Agent 2: Joe","text":"<ol> <li>Add another agent to the canvas and name it Joe.</li> <li>Set the description to \"Joe is a standup comedian.\"</li> <li>In the System Message field, enter: <code>Your name is Joe and you are a standup comedian. Start the next joke from the previous punchline.</code></li> <li>Link the <code>gpt-3.5-turbo</code> model to Joe.</li> <li>Save the configuration.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#link-agents","title":"Link Agents","text":"<ol> <li>In the Waldiez canvas, create a chat link between Joe and Cathy.</li> <li>Click on the link and configure the following settings:<ul> <li>Chat Type: Leave this as is: \"Chat.\"</li> <li>Name: <code>Joe =&gt; Cathy</code>.</li> <li>Max Turns: Specify the number of turns for their exchange (e.g., 3).</li> </ul> </li> <li>Click Save to apply the settings.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#update-the-flows-settings","title":"Update the Flow's settings","text":"<ol> <li>Open the Edit Flow settings.</li> <li>Name the flow, e.g., Standup comedians 1, and add a description like \"Standup comedians with user input.\"</li> <li>Add the chat link <code>Joe =&gt; Cathy</code> to the flow sequence to specify the conversation order.</li> <li>Save the flow configuration.</li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#initiate-the-chat","title":"Initiate the Chat","text":"<ol> <li>Click on the Run button to start the flow.</li> <li> <p>Start the flow by providing an initial message in the User Input window, such as:</p> <p><code>Hi Cathy, I'm Joe. Let's keep the jokes rolling!</code></p> </li> <li> <p>Click Submit to begin the conversation.</p> </li> </ol>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#observe-the-conversation-in-logs","title":"Observe the Conversation in Logs","text":"<ul> <li>The Logs window will display the real-time exchange between Joe and Cathy, where each agent responds based on the previous joke or statement, simulating a standup comedy routine.</li> </ul>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#review-and-export-results","title":"Review and Export Results","text":"<ul> <li>After the conversation, various CSV logs (e.g., <code>agents.csv</code>, <code>chat_completions.csv</code>) are saved in the file explorer. You can analyze these logs to evaluate the flow and refine the agent interactions.</li> </ul>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#skipping-user-input","title":"Skipping user input","text":"<p>To skip user input and directly start the conversation, you can modify the chat link settings to start with a specific message. Set the message type as \"Text\" and set the desired starting message to the content field.  This way, the agents will begin the conversation without waiting for user input.</p> <p> </p>"},{"location":"blog/2024/11/02/multi-agent-conversation-and-stand-up-comedy.html#using-a-termination-condition","title":"Using a termination condition","text":"<p>You can also disable the \"max turns\" setting in the chat link and use a termination condition to end the conversation based on specific criteria. Specify the termination settings in each agent's configuration to control the flow's duration and completion.</p> <p> </p> <p>Also, make sure you update the agents' system messages to reflect the termination condition.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Using User input: Standup Comedians 1.waldiez</li> <li>Without user input: Standup Comedians 2.waldiez</li> <li>Without user input and max turns (termination): Standup Comedians 3.waldiez</li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html","title":"Sequential Chats and Customer Onboarding","text":"<p>This guide explains how to configure and execute a customer onboarding flow using various agents. Each agent has a specific role, working together to gather user information, understand preferences, and provide engaging content.</p>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#agent-roles","title":"Agent Roles","text":"<ol> <li>personal_information_agent: Collects the user's name and location.</li> <li>topic_preference_agent: Asks the user about their topics of interest.</li> <li>customer_engagement_agent: Uses the collected information and preferences to share engaging content.</li> <li>customer_proxy: Acts as an intermediary to pass information between agents.</li> </ol>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#models-used","title":"Models used","text":"<p>Feel free to use any models that suit your requirements. Here are the models used in this example:</p> <ul> <li>personal_information_agent: <code>claude-3.5-sonnet-20240620</code></li> <li>topic_preference_agent: <code>claude-3.5-sonnet-20240620</code></li> <li>customer_engagement_agent: <code>gpt-3.5-turbo</code></li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#agents-setup","title":"Agents Setup","text":""},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#1-configure-personal_information_agent","title":"1. Configure <code>personal_information_agent</code>","text":"<ul> <li>Purpose: Gather basic information (name, location).</li> <li>Settings:<ul> <li>Model: <code>claude-3.5-sonnet-20240620</code></li> <li>System Message: \"You are a helpful customer on-boarding agent, you are here to help new customers get started with our product. Your job is to gather customer's name and location. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#2-configure-topic_preference_agent","title":"2. Configure <code>topic_preference_agent</code>","text":"<ul> <li>Purpose: Gather the customer\u2019s topics of interest.</li> <li>Settings:<ul> <li>Model: <code>claude-3.5-sonnet-20240620</code></li> <li>System Message: \"You are a helpful customer topic preference agent, you are here to help new customers get started with our product. Your job is to gather customer's topic of interest. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#3-configure-customer_engagement_agent","title":"3. Configure <code>customer_engagement_agent</code>","text":"<ul> <li>Purpose: Provide engaging content based on user preferences and location.</li> <li>Settings:<ul> <li>Model: <code>gpt-3.5-turbo</code></li> <li>System Message: \"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#4-configure-customer_proxy","title":"4. Configure <code>customer_proxy</code>","text":"<ul> <li>Purpose: Intermediate agent to handle information passing between other agents.</li> <li>Settings:<ul> <li>Human Input Mode: <code>Always</code></li> </ul> </li> </ul>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#agent-connections","title":"Agent Connections","text":"<ol> <li> <p>personal_information_agent =&gt; customer_proxy</p> <ul> <li>Message Configuration:<ul> <li>Message Type: Text</li> <li>Message Content: \"Hello, I'm here to help you get started with our product. Could you tell me your name and location?\" --&gt;</li> </ul> </li> <li>Summary Method: Reflection with LLM</li> <li> <p>Summary Prompt: \"Return the customer information as JSON object only: <code>{\"name\": \"\", \"location\": \"\"}</code>.\"</p> <p> </p> </li> </ul> </li> <li> <p>topic_preference_agent =&gt; customer_proxy</p> <ul> <li>Message Configuration:<ul> <li>Message Type: Text</li> <li>Message Content: \"Great! Could you tell me what topics you are interested in reading about?\"</li> </ul> </li> <li>Summary Method: Reflection with LLM</li> <li> <p>Summary Prompt: \"Return the topic of interest as JSON: <code>{\"topic_of_interest\": \"\"}</code>.\"</p> <p> </p> </li> </ul> </li> <li> <p>customer_proxy =&gt; customer_engagement_agent</p> <ul> <li>Message Configuration:     - Message Type: Text     - Message Content: \"Let's find something fun to read.\"</li> </ul> </li> </ol>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#define-the-flow-order","title":"Define the Flow Order","text":"<p>Before running the flow, make sure the execution order is configured:</p> <ol> <li>Open the Edit Flow modal.</li> <li>Set the Order as follows:<ul> <li><code>personal_inform =&gt; customer_proxy</code></li> <li><code>topic_preference =&gt; customer_proxy</code></li> <li><code>customer_proxy =&gt; customer_engage</code></li> </ul> </li> <li>Save the flow.</li> </ol> <p> </p>"},{"location":"blog/2024/11/02/sequential-chats-and-customer-onboarding.html#running-the-flow","title":"Running the Flow","text":"<ol> <li> <p>Initialize the Conversation:</p> <ul> <li>The <code>personal_information_agent</code> asks for the user's name and location.</li> <li>Example Response: \"Hi, I'm Stella from Athens.\"</li> </ul> </li> <li> <p>Capture User Preferences:</p> <ul> <li>The <code>topic_preference_agent</code> asks for topics of interest.</li> <li>Example Response: \"Software Agents.\"</li> </ul> </li> <li> <p>Engage the Customer:</p> <ul> <li>The <code>customer_engagement_agent</code> uses the data to provide a fun fact or engaging information.</li> <li>Example Response to User: \"Hey Stella from Athens! Did you know that the word 'robot' comes from the Czech word 'robota', which means forced labor? It's interesting when thinking about software agents!\"</li> </ul> </li> </ol> <p>Files used in this example:</p> <ul> <li>On-boarding Flow: On-boarding.waldiez</li> </ul>"},{"location":"contribute/index.html","title":"Contribute","text":""},{"location":"contribute/index.html#contributing-to-waldiez-projects","title":"Contributing to Waldiez Projects","text":"<p>Thank you for your interest in contributing to the Waldiez repositories! Below, you\u2019ll find the guidelines for contributing code, documentation, and ideas to our various projects. We welcome contributions of all types, including new features, bug fixes, and documentation improvements.</p>"},{"location":"contribute/index.html#1-getting-started","title":"1. Getting Started","text":"<ul> <li>Fork the Repository: Fork the repository you want to contribute to by clicking the \"Fork\" button on GitHub.</li> <li> <p>Clone Your Fork: Clone the forked repository to your local machine.     </p> <p><code>git clone https://github.com/YOU/REPOSITORY-NAME.git</code></p> </li> </ul> <ul> <li> <p>Set Upstream: Add the original repository as a remote upstream.</p> <p><code>git remote add upstream https://github.com/waldiez/REPOSITORY-NAME.git</code></p> </li> </ul> <ul> <li>Check for Requirements: Some projects may have specific dependencies or setup instructions listed in a <code>README</code> or <code>CONTRIBUTING.md</code> file within the repository.</li> </ul>"},{"location":"contribute/index.html#2-contribution-guidelines","title":"2. Contribution Guidelines","text":"<p>Before making any changes, please read through our organization-wide contribution guidelines:</p> <ul> <li>Open an Issue First: For larger changes, open an issue to discuss your proposed changes with the maintainers. This helps avoid duplicate work and ensures alignment with project goals.</li> <li>Follow the Code of Conduct: Review and adhere to our Code of Conduct.</li> <li>Respect Repository Owners: Each repository may have its own set of maintainers or reviewers. Follow their guidelines for submitting work and await feedback before merging.</li> </ul>"},{"location":"contribute/index.html#3-submitting-issues","title":"3. Submitting Issues","text":"<p>If you notice a bug or have a feature request:</p> <ul> <li>Check Existing Issues: Before creating a new issue, search the issues in the repository to avoid duplicates.</li> <li>Open a New Issue: Use a descriptive title and include any necessary details (e.g., steps to reproduce for bugs).</li> <li>Add Labels: If possible, label your issue as a <code>bug</code>, <code>enhancement</code>, <code>documentation</code>, or <code>question</code>.</li> <li>Follow the Issue Template (if available): Some repositories may have specific templates for bug reports, feature requests, etc.</li> </ul>"},{"location":"contribute/index.html#4-working-on-issues","title":"4. Working on Issues","text":"<p>If you want to work on an existing issue:</p> <ul> <li>Check for an Assignee: If no one is assigned, comment on the issue and ask to be assigned.</li> <li>Claim the Issue: Wait for a maintainer to assign the issue to you to avoid duplicate work.</li> <li>Create a New Branch: Use a descriptive name for your branch.<p>git checkout -b feature/your-feature-name</p> </li> </ul>"},{"location":"contribute/index.html#5-submitting-pull-requests","title":"5. Submitting Pull Requests","text":"<p>When you\u2019re ready to submit your changes:</p> <ul> <li>Sync with Upstream: Pull the latest changes from the upstream repository and resolve any conflicts.<p>git fetch upstream   git merge upstream/main</p> </li> </ul> <ul> <li>Create a Pull Request: Push your branch to your fork and open a pull request (PR) to the original repository.</li> </ul> <ul> <li>Write a Descriptive Title and Message: Briefly describe your changes and the issue it addresses.</li> </ul> <ul> <li>Link the Related Issue: Use keywords like <code>Closes #ISSUE_NUMBER</code> to link to the relevant issue.</li> </ul> <ul> <li>Await Review: A maintainer will review your PR. Be ready to make changes based on feedback.</li> </ul>"},{"location":"contribute/index.html#6-code-style-best-practices","title":"6. Code Style &amp; Best Practices","text":"<p>To maintain code consistency:</p> <ul> <li>Follow Project Coding Standards: Refer to any coding guidelines or <code>.editorconfig</code> /<code>eslint</code> / <code>flake8</code> / <code>pyproject.toml</code> files in the repository.</li> <li>Write Tests: Ensure new features or fixes are covered by tests, where applicable.</li> <li>Add Documentation: If your changes require updates to the documentation, make those in the appropriate files.</li> </ul>"},{"location":"contribute/index.html#7-project-specific-instructions","title":"7. Project-Specific Instructions","text":"<p>Some repositories may have additional instructions:</p> <ul> <li>waldiez/waldiez: The core python part of the project. Responsible for converting waldiez flows to python scripts and jupyter notebooks, as well as running them.</li> <li>waldiez/react: The frontend part of the project. Responsible for creating the user interface for waldiez flows.</li> <li>waldiez/jupyter: It combines the python and react parts above. It is responsible for running the python scripts and jupyter notebooks created by the user.</li> <li>waldiez/studio: A standalone (without jupyter) web app that also combines the python and react parts above. Once ready, it will be included as an extra requirement in the waldiez pypi package.</li> <li>waldiez/vscode: A waldiez vscode extension: Open .waldiez files in vscode convert them to python scripts and jupyter notebooks, and run them.</li> </ul> <p>Refer to the <code>README.md</code> or <code>CONTRIBUTING.md</code> of each repository for detailed information.</p>"},{"location":"contribute/index.html#8-resources","title":"8. Resources","text":"<ul> <li>Git and GitHub Guide</li> <li>GitHub Flow</li> </ul> <p>We appreciate your contributions! \ud83c\udf89</p>"},{"location":"examples/index.html","title":"Examples","text":""},{"location":"examples/index.html#table-of-contents","title":"Table of Contents","text":"<ul> <li>Multi-Agent Conversation and Stand up Comedy</li> <li>Sequential Chats and Customer Onboarding</li> <li>Reflection and Blog post Writing</li> <li>Tool Use and Conversational Chess</li> <li>Coding and Financial Analysis</li> <li>Planning and Stock Report Generation</li> <li>Group Chat with Retrieval Augmented Generation</li> <li>ReAct using Tavily</li> </ul> <p>Note</p> <p>The provided examples are inspired by the following sources:</p> <ul> <li>AI Agentic Design Patterns with AutoGen</li> <li>AG2 Examples</li> </ul>"},{"location":"examples/1.html","title":"Standup Comedians","text":""},{"location":"examples/1.html#multi-agent-conversation-and-stand-up-comedy","title":"Multi-Agent Conversation and Stand up Comedy","text":"<p>This guide walks you through creating a conversational flow in JupyterLab using the Waldiez extension, where two agents, \"Joe\" and \"Cathy,\" simulate a standup comedy exchange. We will configure an OpenAI model (GPT-3.5-turbo) for this flow and observe the interaction between the agents.</p>"},{"location":"examples/1.html#using-user-input-to-start-the-conversation","title":"Using user input to start the conversation","text":"<p>In this example, we will set up a flow where the user initiates the conversation by providing an initial message. The agents, Joe and Cathy, will then respond to each other based on the user input and the previous agent's message.</p>"},{"location":"examples/1.html#open-jupyterlab-and-launch-waldiez","title":"Open JupyterLab and Launch Waldiez","text":"<ol> <li>Start JupyterLab.</li> <li>In the launcher, under the Waldiez section, select the Waldiez icon to create a new <code>.waldiez</code> file. This opens a new interface for setting up agents and configuring the flow.</li> </ol>"},{"location":"examples/1.html#add-a-model","title":"Add a Model","text":"<ol> <li>In the Waldiez interface, click on <code>Add model</code> to add a new model configuration.</li> <li>Fill out the configuration fields:<ul> <li>Name: <code>gpt-3.5-turbo</code></li> <li>Model Type: Select <code>OpenAI</code>.</li> <li>API Key: Enter your OpenAI API key (make sure you have GPT-3.5-turbo access).</li> </ul> </li> <li>Optionally adjust Advanced Settings like Temperature and Max Tokens as per your needs.</li> <li>Click Save to add the model to your flow.</li> </ol>"},{"location":"examples/1.html#create-agents","title":"Create Agents","text":""},{"location":"examples/1.html#agent-1-cathy","title":"Agent 1: Cathy","text":"<ol> <li>Under the <code>Agents</code> section, drag a new agent onto the canvas.</li> <li>Name the agent Cathy.</li> <li>Set the description to \"Cathy is a standup comedian.\"</li> <li>In the System Message field, enter: <code>Your name is Cathy and you are a standup comedian.</code></li> <li>Link the <code>gpt-3.5-turbo</code> model to Cathy by selecting it in the Models tab.</li> <li>Save the configuration.</li> </ol>"},{"location":"examples/1.html#agent-2-joe","title":"Agent 2: Joe","text":"<ol> <li>Add another agent to the canvas and name it Joe.</li> <li>Set the description to \"Joe is a standup comedian.\"</li> <li>In the System Message field, enter: <code>Your name is Joe and you are a standup comedian. Start the next joke from the previous punchline.</code></li> <li>Link the <code>gpt-3.5-turbo</code> model to Joe.</li> <li>Save the configuration.</li> </ol>"},{"location":"examples/1.html#link-agents","title":"Link Agents","text":"<ol> <li>In the Waldiez canvas, create a chat link between Joe and Cathy.</li> <li>Click on the link and configure the following settings:<ul> <li>Chat Type: Leave this as is: \"Chat.\"</li> <li>Name: <code>Joe =&gt; Cathy</code>.</li> <li>Max Turns: Specify the number of turns for their exchange (e.g., 3).</li> </ul> </li> <li>Click Save to apply the settings.</li> </ol>"},{"location":"examples/1.html#update-the-flows-settings","title":"Update the Flow's settings","text":"<ol> <li>Open the Edit Flow settings.</li> <li>Name the flow, e.g., Standup comedians 1, and add a description like \"Standup comedians with user input.\"</li> <li>Add the chat link <code>Joe =&gt; Cathy</code> to the flow sequence to specify the conversation order.</li> <li>Save the flow configuration.</li> </ol>"},{"location":"examples/1.html#initiate-the-chat","title":"Initiate the Chat","text":"<ol> <li>Click on the Run button to start the flow.</li> <li> <p>Start the flow by providing an initial message in the User Input window, such as:</p> <p><code>Hi Cathy, I'm Joe. Let's keep the jokes rolling!</code></p> </li> <li> <p>Click Submit to begin the conversation.</p> </li> </ol>"},{"location":"examples/1.html#observe-the-conversation-in-logs","title":"Observe the Conversation in Logs","text":"<ul> <li>The Logs window will display the real-time exchange between Joe and Cathy, where each agent responds based on the previous joke or statement, simulating a standup comedy routine.</li> </ul>"},{"location":"examples/1.html#review-and-export-results","title":"Review and Export Results","text":"<ul> <li>After the conversation, various CSV logs (e.g., <code>agents.csv</code>, <code>chat_completions.csv</code>) are saved in the file explorer. You can analyze these logs to evaluate the flow and refine the agent interactions.</li> </ul>"},{"location":"examples/1.html#skipping-user-input","title":"Skipping user input","text":"<p>To skip user input and directly start the conversation, you can modify the chat link settings to start with a specific message. Set the message type as \"Text\" and set the desired starting message to the content field.  This way, the agents will begin the conversation without waiting for user input.</p> <p> </p>"},{"location":"examples/1.html#using-a-termination-condition","title":"Using a termination condition","text":"<p>You can also disable the \"max turns\" setting in the chat link and use a termination condition to end the conversation based on specific criteria. Specify the termination settings in each agent's configuration to control the flow's duration and completion.</p> <p> </p> <p>Also, make sure you update the agents' system messages to reflect the termination condition.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Using User input: Standup Comedians 1.waldiez</li> <li>Without user input: Standup Comedians 2.waldiez</li> <li>Without user input and max turns (termination): Standup Comedians 3.waldiez</li> </ul>"},{"location":"examples/2.html","title":"Onboarding","text":""},{"location":"examples/2.html#sequential-chats-and-customer-onboarding","title":"Sequential Chats and Customer Onboarding","text":"<p>This guide explains how to configure and execute a customer onboarding flow using various agents. Each agent has a specific role, working together to gather user information, understand preferences, and provide engaging content.</p>"},{"location":"examples/2.html#agent-roles","title":"Agent Roles","text":"<ol> <li>personal_information_agent: Collects the user's name and location.</li> <li>topic_preference_agent: Asks the user about their topics of interest.</li> <li>customer_engagement_agent: Uses the collected information and preferences to share engaging content.</li> <li>customer_proxy: Acts as an intermediary to pass information between agents.</li> </ol>"},{"location":"examples/2.html#models-used","title":"Models used","text":"<p>Feel free to use any models that suit your requirements. Here are the models used in this example:</p> <ul> <li>personal_information_agent: <code>claude-3.5-sonnet-20240620</code></li> <li>topic_preference_agent: <code>claude-3.5-sonnet-20240620</code></li> <li>customer_engagement_agent: <code>gpt-3.5-turbo</code></li> </ul>"},{"location":"examples/2.html#agents-setup","title":"Agents Setup","text":""},{"location":"examples/2.html#1-configure-personal_information_agent","title":"1. Configure <code>personal_information_agent</code>","text":"<ul> <li>Purpose: Gather basic information (name, location).</li> <li>Settings:<ul> <li>Model: <code>claude-3.5-sonnet-20240620</code></li> <li>System Message: \"You are a helpful customer on-boarding agent, you are here to help new customers get started with our product. Your job is to gather customer's name and location. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"examples/2.html#2-configure-topic_preference_agent","title":"2. Configure <code>topic_preference_agent</code>","text":"<ul> <li>Purpose: Gather the customer\u2019s topics of interest.</li> <li>Settings:<ul> <li>Model: <code>claude-3.5-sonnet-20240620</code></li> <li>System Message: \"You are a helpful customer topic preference agent, you are here to help new customers get started with our product. Your job is to gather customer's topic of interest. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"examples/2.html#3-configure-customer_engagement_agent","title":"3. Configure <code>customer_engagement_agent</code>","text":"<ul> <li>Purpose: Provide engaging content based on user preferences and location.</li> <li>Settings:<ul> <li>Model: <code>gpt-3.5-turbo</code></li> <li>System Message: \"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\"</li> <li>Termination Keyword: <code>TERMINATE</code></li> </ul> </li> </ul>"},{"location":"examples/2.html#4-configure-customer_proxy","title":"4. Configure <code>customer_proxy</code>","text":"<ul> <li>Purpose: Intermediate agent to handle information passing between other agents.</li> <li>Settings:<ul> <li>Human Input Mode: <code>Always</code></li> </ul> </li> </ul>"},{"location":"examples/2.html#agent-connections","title":"Agent Connections","text":"<ol> <li> <p>personal_information_agent =&gt; customer_proxy</p> <ul> <li>Message Configuration:<ul> <li>Message Type: Text</li> <li>Message Content: \"Hello, I'm here to help you get started with our product. Could you tell me your name and location?\" --&gt;</li> </ul> </li> <li>Summary Method: Reflection with LLM</li> <li> <p>Summary Prompt: \"Return the customer information as JSON object only: <code>{\"name\": \"\", \"location\": \"\"}</code>.\"</p> <p> </p> </li> </ul> </li> <li> <p>topic_preference_agent =&gt; customer_proxy</p> <ul> <li>Message Configuration:<ul> <li>Message Type: Text</li> <li>Message Content: \"Great! Could you tell me what topics you are interested in reading about?\"</li> </ul> </li> <li>Summary Method: Reflection with LLM</li> <li> <p>Summary Prompt: \"Return the topic of interest as JSON: <code>{\"topic_of_interest\": \"\"}</code>.\"</p> <p> </p> </li> </ul> </li> <li> <p>customer_proxy =&gt; customer_engagement_agent</p> <ul> <li>Message Configuration:     - Message Type: Text     - Message Content: \"Let's find something fun to read.\"</li> </ul> </li> </ol>"},{"location":"examples/2.html#define-the-flow-order","title":"Define the Flow Order","text":"<p>Before running the flow, make sure the execution order is configured:</p> <ol> <li>Open the Edit Flow modal.</li> <li>Set the Order as follows:<ul> <li><code>personal_inform =&gt; customer_proxy</code></li> <li><code>topic_preference =&gt; customer_proxy</code></li> <li><code>customer_proxy =&gt; customer_engage</code></li> </ul> </li> <li>Save the flow.</li> </ol> <p> </p>"},{"location":"examples/2.html#running-the-flow","title":"Running the Flow","text":"<ol> <li> <p>Initialize the Conversation:</p> <ul> <li>The <code>personal_information_agent</code> asks for the user's name and location.</li> <li>Example Response: \"Hi, I'm Stella from Athens.\"</li> </ul> </li> <li> <p>Capture User Preferences:</p> <ul> <li>The <code>topic_preference_agent</code> asks for topics of interest.</li> <li>Example Response: \"Software Agents.\"</li> </ul> </li> <li> <p>Engage the Customer:</p> <ul> <li>The <code>customer_engagement_agent</code> uses the data to provide a fun fact or engaging information.</li> <li>Example Response to User: \"Hey Stella from Athens! Did you know that the word 'robot' comes from the Czech word 'robota', which means forced labor? It's interesting when thinking about software agents!\"</li> </ul> </li> </ol> <p>Files used in this example:</p> <ul> <li>On-boarding Flow: On-boarding.waldiez</li> </ul>"},{"location":"examples/3.html","title":"Reflection","text":""},{"location":"examples/3.html#reflection-and-blog-post-writing","title":"Reflection and Blog post Writing","text":"<p>In this example, we will setup up a workflow for reviewing and improving blog posts using nested chats. The workflow includes roles for a writer, critic, and various reviewers (SEO, Legal, Ethics, and Meta).</p>"},{"location":"examples/3.html#agent-roles","title":"Agent Roles","text":"<ul> <li>Writer: Writes blog posts based on given topics.</li> <li>Critic: Asks for reviews and provides feedback on the writer's work.</li> <li>SEO Reviewer: Optimizes content for search engines.</li> <li>Legal Reviewer: Ensures content is legally compliant.</li> <li>Ethics Reviewer: Ensures content is ethically sound.</li> <li>Meta Reviewer: Aggregates feedback from other reviewers.</li> </ul>"},{"location":"examples/3.html#models-used","title":"Models Used","text":"<p>Feel free to use any models that suit your requirements. Here are the models used in this example:</p> <ul> <li>SEO Reviewer: <code>gpt-3.5-turbo</code></li> <li>Legal Reviewer: <code>gpt-3.5-turbo</code></li> <li>Ethics Reviewer: <code>gpt-3.5-turbo</code></li> <li>Meta Reviewer: <code>gpt-3.5-turbo</code></li> <li>Writer: <code>gpt-3.5-turbo</code></li> <li>Critic: <code>gpt-3.5-turbo</code></li> </ul>"},{"location":"examples/3.html#setup-the-agents","title":"Setup the Agents","text":""},{"location":"examples/3.html#seo-reviewer","title":"SEO Reviewer","text":"<ol> <li>Add an agent named SEO reviewer.</li> <li> <p>In the System Message, set:</p> <pre><code>You are an SEO reviewer, known for your ability to optimize content for search engines, ensuring that it ranks well and attracts organic traffic. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol>"},{"location":"examples/3.html#legal-reviewer","title":"Legal Reviewer","text":"<ol> <li>Add an agent named Legal reviewer.</li> <li> <p>In the System Message, set:</p> <pre><code>You are a legal reviewer, known for your ability to ensure that content is legally compliant and free from any potential legal issues. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol>"},{"location":"examples/3.html#ethics-reviewer","title":"Ethics Reviewer","text":"<ol> <li>Add an agent named Ethics reviewer.</li> <li> <p>In the System Message, set:</p> <pre><code>You are an ethics reviewer, known for your ability to ensure that content is ethically sound and free from any potential ethical issues. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol>"},{"location":"examples/3.html#meta-reviewer","title":"Meta Reviewer","text":"<ol> <li>Add an agent named Meta reviewer.</li> <li> <p>In the System Message, set:</p> <pre><code>You are a meta reviewer, you aggregate and review the work of other reviewers and give a final suggestion on the content.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol>"},{"location":"examples/3.html#writer-agent","title":"Writer Agent","text":"<ol> <li>Add a new agent named Writer.</li> <li> <p>In the System Message, set:</p> <pre><code>You are a writer. You write engaging and concise blog posts (with title) on given topics. You must polish your writing based on the feedback you receive and give a refined version. Only return your final work without additional comments.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol>"},{"location":"examples/3.html#critic-agent","title":"Critic Agent","text":"<ol> <li>Add a new agent named Critic.</li> <li> <p>In the System Message, set:</p> <pre><code>You are a critic. You review the work of the writer and provide constructive feedback to help improve the quality of the content.\n</code></pre> </li> <li> <p>Link the agent to a model.</p> </li> </ol> <p>Note</p> <p>We will come back to the Critic agent to configure nested chats after setting up the agent connections.</p>"},{"location":"examples/3.html#agent-connections","title":"Agent Connections","text":""},{"location":"examples/3.html#writer-critic","title":"Writer =&gt; Critic","text":"<ol> <li>Connect the Critic agent to the Writer agent.</li> <li>On the message tab, set the type to \"Text\" and the content to:<pre><code>Write a concise but engaging blog post about DeepLearning.AI. Make sure the blog post is within 100 words.\n</code></pre> </li> </ol>"},{"location":"examples/3.html#nested-chats","title":"Nested chats","text":"<p>For the rest of the connections, we will set up nested chats to gather feedback from the SEO, Legal, Ethics, and Meta reviewers. Add a link from the Critic agent to each of the reviewers, and set the chat type to \"Nested Chat\". Set Max turns to 1 and Summary method to \"Last Message\". For the nested chat content, we will use a custom method to send the content to the SEO, Legal, and Ethics reviewers:</p> <pre><code>def nested_chat_message(recipient, messages, sender, config):\n\"\"\"Ask for a review.\"\"\"\nreturn f\"\"\"Review the following content.\n        \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\"\"\n</code></pre> <p> </p> <p>For the Meta reviewer, we use the \"Text\" type:</p> <pre><code>Aggregate feedback from all reviewers and give final suggestions on the writing.\n</code></pre>"},{"location":"examples/3.html#nested-chat-registration","title":"Nested chat registration","text":"<ol> <li>Go to the Critic agent\u2019s settings and navigate to the Nested Chats tab.</li> <li>The nested chat is triggered when the writer replies to the critic's message with the content to be reviewed, so on the \"Triggered by\" select the Writer agent and check the \"Agent's reply\" box.</li> <li>Set up the messages to be sent when the chat is triggered:<ul> <li>Critic =&gt; SEO reviewer</li> <li>Critic =&gt; Legal reviewer</li> <li>Critic =&gt; Ethics reviewer</li> <li>Critic =&gt; Meta reviewer</li> </ul> </li> </ol>"},{"location":"examples/3.html#4-workflow-flow-order","title":"4. Workflow Flow Order","text":"<ol> <li>Open the Edit Flow menu.</li> <li>Name the flow as Reflection or another suitable name.</li> <li>Set the initial flow order to start with Critic =&gt; Writer.</li> </ol>"},{"location":"examples/3.html#5-run-the-flow","title":"5. Run the flow","text":"<p>We are ready to run the flow. Hit the play button to start the flow. The critic will ask the writer to write a blog post about DeepLearning.AI. The writer will then write the blog post and send it to the critic for review. The critic will then send the content to the SEO, Legal, Ethics, and Meta reviewers for feedback. You can check the logs to see the flow of the conversation.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Flow: Reflection.waldiez</li> </ul>"},{"location":"examples/4.html","title":"Tool Use","text":""},{"location":"examples/4.html#tool-use-and-conversational-chess","title":"Tool Use and Conversational Chess","text":"<p>In this example, we build a conversational chess game using three agents: Player White, Player Black, and Board Proxy. The agents interact to play a game of chess, with each player taking turns to make moves. The Board Proxy manages the board state and facilitates communication between the players.</p> <p> </p> <p>Note</p> <p>Can you find a better way to handle the board state and move tracking between agents, without using globals? Give it a try! We'd love to hear your feedback on this example, either by contributing to the repository, or by reaching out to us.</p>"},{"location":"examples/4.html#overview","title":"Overview","text":"<p>The flow includes:</p> <ul> <li>Player White and Player Black agents for each chess player.</li> <li>Board Proxy to manage board state and relay information between players.</li> </ul>"},{"location":"examples/4.html#agents-and-skills","title":"Agents and Skills","text":""},{"location":"examples/4.html#agents","title":"Agents","text":"<ol> <li>Player White: The agent playing white pieces. Calls methods to get legal moves and make moves.</li> <li>Player Black: The agent playing black pieces. Operates similarly to Player White.</li> <li>Board Proxy: Manages the board\u2019s state and facilitates move tracking between agents.</li> </ol>"},{"location":"examples/4.html#skills","title":"Skills","text":"<p>Each player has access to the following skills:</p> <ul> <li>get_legal_moves: Fetches the list of legal moves in UCI format.</li> <li>make_move: Executes a move and provides feedback on the action taken.</li> </ul> <p> </p>"},{"location":"examples/4.html#get_legal_moves","title":"get_legal_moves","text":"<p>This function generates a list of possible legal moves from the current board state.</p> <ul> <li> <p>Content:</p> <pre><code>from typing import Annotated\n\n import chess\n\n if \"BOARD\" not in globals():\n     BOARD = chess.Board()\n     globals()[\"BOARD\"] = BOARD\n else:\n     BOARD = globals()[\"BOARD\"]\n\n\n def get_legal_moves() -&gt; Annotated[str, \"A list of legal moves in UCI format\"]:\n     \"\"\"Get a list of legal moves.\"\"\"\n     return \"Possible moves are: \" + \",\".join(\n     [str(move) for move in BOARD.legal_moves]\n )\n</code></pre> </li> </ul>"},{"location":"examples/4.html#make_move","title":"make_move","text":"<p>Executes a chosen move and outputs the result.</p> <ul> <li>Content:<pre><code>from typing import Annotated\nimport chess\n# Global variables to store the board and move status.\nif \"BOARD\" not in globals():\n    BOARD = chess.Board()\n    globals()[\"BOARD\"] = BOARD\nelse:\n    BOARD = globals()[\"BOARD\"]\nif \"MADE_MOVE\" not in globals():\n    MADE_MOVE = False\n    globals()[\"MADE_MOVE\"] = MADE_MOVE\nelse:\n    MADE_MOVE = globals()[\"MADE_MOVE\"]\n\ndef make_move(\n    move: Annotated[str, \"A move in UCI format.\"],\n) -&gt; Annotated[str, \"Result of the move.\"]:\n    \"\"\"Make a move on the board.\"\"\"\n    global MADE_MOVE\n    try:\n        move = chess.Move.from_uci(move)\n    except BaseException:  # pylint: disable=broad-except\n        move = BOARD.parse_san(move)\n    BOARD.push_uci(str(move))\n    # Get the piece name.\n    piece = BOARD.piece_at(move.to_square)\n    piece_symbol = piece.unicode_symbol()\n    piece_name = (\n        chess.piece_name(piece.piece_type).capitalize()\n        if piece_symbol.isupper()\n        else chess.piece_name(piece.piece_type)\n    )\n    MADE_MOVE = True\n    return f\"Moved {piece_name} ({piece_symbol}) from \"\\\n        f\"{chess.SQUARE_NAMES[move.from_square]} to \"\\\n        f\"{chess.SQUARE_NAMES[move.to_square]}.\"\n</code></pre> </li> </ul>"},{"location":"examples/4.html#agent-configuration","title":"Agent Configuration","text":"<ol> <li> <p>Player White and Player Black Agents:</p> <ul> <li>System Message: You are a chess player and you play as black / white. First call get_legal_moves(), to get a list of legal moves. Then call make_move(move) to make a move.</li> <li> <p>Skills: Assign <code>get_legal_moves</code> and <code>make_move</code> to each agent. Set the executor to the board proxy.</p> <p> </p> </li> </ul> </li> <li> <p>Board Proxy:</p> <ul> <li> <p>Termination Method: Set up a termination method to end the conversation after a move is made. This method resets a flag (<code>MADE_MOVE</code>) after each move to monitor the game flow.</p> <p> </p> </li> </ul> </li> </ol>"},{"location":"examples/4.html#chats","title":"Chats","text":"<p>The flow starts with the black player challenging the white player to a game of chess. The white player then makes the first move.</p> <ul> <li>Player Black =&gt; Player White: The black player challenges the white player to a game of chess. For the message we use the \"Text\" type and for content, we use:<pre><code>Let's play chess! Your move.\n</code></pre> </li> </ul> <ul> <li>Player White =&gt; Board Proxy: When the white player receives the challenge, a new nested chat is triggered to get the move to play using the board proxy.</li> </ul> <ul> <li>Player Black =&gt; Board Proxy: When the black player gets a reply from the white player, a new nested chat is triggered to get the move to play using the board proxy. And the beat goes on!<p> </p> </li> </ul>"},{"location":"examples/4.html#register-nested-chats","title":"Register Nested Chats","text":"<p>On each agent, set up the nested chats we defined above, to handle the flow of the game. For the white player, a nested chat is triggered when the black player makes a move. For the black player, a nested chat is triggered when the white player replies. The message to use is the board proxy's reply, after a new move is made.</p> <p> </p>"},{"location":"examples/4.html#flow-chats-and-requirements","title":"Flow chats and requirements","text":"<ol> <li>Edit Flow: Set up the flow order to start with the \"Player Black =&gt; Player White\" connection.</li> <li>Additional requirements: As we have seen, running the flow requires the usage of the \"chess\" library, so make sure to add it in the \"Other\" tab      </li> </ol> <p>Files used in this example:</p> <ul> <li>Flow: Tool Use.waldiez</li> <li>Skills:<ul> <li>get_legal_moves.waldiezSkill</li> <li>make_move.waldiezSkill</li> </ul> </li> </ul>"},{"location":"examples/5.html","title":"Coding","text":""},{"location":"examples/5.html#coding-and-financial-analysis","title":"Coding and Financial Analysis","text":"<p>In this example, we will set up a workflow for retrieving and plotting stock prices over a specified period. The workflow includes agents for data retrieval, data plotting, and message handling.</p> <p> </p>"},{"location":"examples/5.html#overview","title":"Overview","text":"<p>The flow includes:</p> <ul> <li>Code Executor Agent: Executes the code for retrieving and plotting stock prices.</li> <li>Code Writer Agent: Writes the code for retrieving and plotting stock prices.</li> <li>Get Stock Prices Skill: Fetches stock prices using <code>yfinance</code>.</li> <li>Plot Stock Prices Skill: Plots the stock prices using <code>matplotlib</code>.</li> </ul>"},{"location":"examples/5.html#agents-and-skills","title":"Agents and skills","text":""},{"location":"examples/5.html#skills","title":"Skills","text":"<ol> <li> <p>Get Stock Prices</p> <ul> <li>Description: Get the stock prices for the given stock symbols between the start and end dates.</li> <li>Inputs: <code>stock_symbols</code> (str or list), <code>start_date</code> (str in <code>YYYY-MM-DD</code>), <code>end_date</code> (str in <code>YYYY-MM-DD</code>).</li> </ul> <p>Content:</p> <pre><code> # filename: {get_stock_prices}.py\n \"\"\"Get stock prices.\n\n Get the stock prices for the given stock symbols between  \n the start and end dates.\n \"\"\"\n\n\n def get_stock_prices(\n     stock_symbols: str | list,\n     start_date: str,\n     end_date: str,\n ):\n     \"\"\"Get the stock prices for the given stock symbols between\n     the start and end dates.\n\n     Args:\n         stock_symbols (str or list): The stock symbols to get the\n         prices for.\n         start_date (str): The start date in the format \n         'YYYY-MM-DD'.\n         end_date (str): The end date in the format 'YYYY-MM-DD'.\n\n     Returns:\n         dict: (pandas.DataFrame.to_dict): The stock prices for the given stock\n         symbols indexed by date, with one column per stock \n         symbol.\n     \"\"\"\n     # pylint: disable=import-outside-toplevel\n     import yfinance\n\n     stock_data = yfinance.download(\n         stock_symbols, start=start_date, end=end_date\n     )\n     return stock_data.get(\"Close\")\n     #\n     # We might get:\n     # Timestamp is not JSON serializable\n     # we can return a dictionary instead:\n     #\n     # close = stock_data.get(\"Close\")\n     # close.index = close.index.date  # Convert the index to date only\n     # close.index = close.index.astype(str)  # Convert the index to string\n     # return close.to_dict()\n</code></pre> <ul> <li>Save the skill.</li> </ul> </li> <li> <p>Skill: Plot Stock Prices</p> <ul> <li>Description: Plot the stock prices for the given stock symbols.</li> </ul> <p>Example Code:</p> <p>```python   # filename: {plot_stock_prices}.py   \"\"\"Plot the stock prices for the given stock symbols.\"\"\"</p> <p>def plot_stock_prices(       stock_prices: dict,       filename: str,   ):       \"\"\"Plot the stock prices for the given stock symbols.</p> <pre><code>  Args:\n      stock_prices (dict) [dumped pandas.DataFrame]: The stock \n          prices for the given stock symbols.\n      filename (str): The filename to save the plot to.\n\n  Returns:\n      str: \"ok\" if the plot was saved successfully.\n  \"\"\"\n  # pylint: disable=import-outside-toplevel\n  import matplotlib.pyplot as plt\n  import pandas as pd\n\n  if isinstance(stock_prices, dict):\n      df = pd.DataFrame.from_dict(stock_prices)\n  else:\n      df = stock_prices\n  plt.figure(figsize=(10, 5))\n  for column in df.columns:\n      plt.plot(df.index, df[column], label=column)\n  plt.title(\"Stock Prices\")\n  plt.xlabel(\"Date\")\n  plt.ylabel(\"Price\")\n  plt.grid(True)\n  # if the days are a lot in the plot, get the xticks every 5 days\n  # plt.xticks(df.index[::5], rotation=45)\n  # give a little space to the plot\n  # or don't use xticks at all\n  # plt.xticks([])\n  plt.tight_layout()\n  # save the plot\n  plt.savefig(filename)\n  return \"ok\"\n</code></pre> <p>```</p> <ul> <li>Save the skill.</li> </ul> </li> </ol>"},{"location":"examples/5.html#agents","title":"Agents","text":""},{"location":"examples/5.html#code-writer-agent","title":"Code Writer Agent","text":"<ol> <li>Models     Link a model of your choice to the Code Writer Agent. In our example, we use the <code>gpt-4-turbo</code> model.</li> <li>Skills     In the skills tab, add the <code>get_stock_prices</code> and <code>plot_stock_prices</code> skills to the Code Writer Agent. As executor, select the Code Executor Agent.      </li> </ol>"},{"location":"examples/5.html#code-executor-agent","title":"Code Executor Agent","text":"<p>In this step, we'll configure a Code Executor Agent to handle the execution of the functions required for retrieving and plotting stock data.</p> <ol> <li> <p>Basic configuration</p> <ul> <li>Max consecutive auto replies: Let's limit the number of auto-replies to <code>10</code> to avoid unnecessary repetition.</li> <li>Agent Default auto-reply: We can set the default auto-reply to `Please continue. If everything is done, reply 'TERMINATE', to avoid repeating the same message when asked.</li> </ul> </li> <li> <p>Code Execution</p> <ul> <li>At the Code Execution tab, check the box for Use Code Execution.</li> <li>Set the Working Directory to <code>coding</code> (or your designated project folder).</li> <li>Set the Timeout slider to <code>60</code> seconds to allow enough time for the code to fetch and plot data without interruption.</li> <li> <p>Under Functions, add the <code>get_stock_prices</code> and <code>plot_stock_prices</code> functions to allow the Code Executor Agent to access and execute these methods.</p> <p> </p> </li> </ul> </li> </ol>"},{"location":"examples/5.html#flow-chats-and-requirements","title":"Flow chats and requirements","text":"<ol> <li>Edit Flow: Set up the flow order to start with the \"Code Executor Agent =&gt; Code Writer\" connection.</li> <li>Additional requirements: Add the libraries we have used (<code>yfinance</code>, <code>matplotlib</code>, <code>pandas</code>) in our skills to the flow requirements.      </li> </ol>"},{"location":"examples/5.html#run-the-flow","title":"Run the flow","text":"<p>Press the Run button to execute the flow. When asked, you can press Enter to use the Agents auto-reply message. When you get a message about having the plot generated, you can enter  <code>TERMINATE</code> (or <code>exit</code>) to end the flow.</p> <p> </p> <p>You can view the generated code and plot in the specified <code>code execution</code> folder.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Flow: Coding.waldiez</li> <li>Skills:<ul> <li>get_stock_prices.waldiezSkill</li> <li>plot_stock_prices.waldiezSkill</li> </ul> </li> </ul> <p>Note</p> <p>The outputs may vary based on the model, skills and message you use. Feel free to customize the skills and messages to suit your requirements</p>"},{"location":"examples/6.html","title":"Planning","text":""},{"location":"examples/6.html#planning-and-stock-report-generation","title":"Planning and Stock Report Generation","text":"<p>In this example, we create a workflow to analyze stock price performance using multiple agents with specific roles. The task is to analyze Nvidia\u2019s stock performance over the past month, retrieve relevant data, and generate a report.</p> <p> </p>"},{"location":"examples/6.html#overview","title":"Overview","text":"<p>The workflow includes:</p> <ul> <li>Admin Agent: Manages task delegation and provides instructions.</li> <li>(Group) Manager Agent: Oversees execution by coordinating with specialized agents.</li> <li>Planner Agent: Plans the sequence of steps to complete the analysis.</li> <li>Engineer Agent: Writes code based on the plan provided by the planner.</li> <li>Executor Agent: Executes the code written by the engineer and reports the result.</li> <li>Writer Agent: Compiles the analysis into a blog post.</li> </ul>"},{"location":"examples/6.html#agents-setup","title":"Agents setup","text":""},{"location":"examples/6.html#admin-agent","title":"Admin Agent","text":"<p>Create a new user proxy agent named <code>Admin</code> and system message:</p> <pre><code>Give the task, and send instructions to writer to refine the blog post.\n</code></pre>"},{"location":"examples/6.html#manager-agent","title":"Manager Agent","text":"<ul> <li>Create a new group agent named <code>Manager</code></li> <li>On the \"Group Chat\" tab, specify the Admin Name and the Max Rounds fields. You can leave the speakers configuration as default (allow speakers repetition, and auto speaker selection method). We'll configure the speaker transitions in a next case.      </li> </ul> <p>Note</p> <p>The Max Rounds field specifies the maximum number of rounds the group agent will run. The group agent will stop after reaching this limit. You might want to set this field to a high number to avoid stopping the group agent prematurely.</p>"},{"location":"examples/6.html#group-members","title":"Group members","text":"<ul> <li> <p>Drag and drop assistant agents to the manager agent:</p> <ul> <li> <p>Planner Agent: Create a new assistant agent named <code>Planner</code> and add the following system message:</p> <pre><code>Given a task, please determine what information is needed to complete the task. Please note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code. After each step is done by others, check the progress and instruct the remaining steps. If a step fails, try to workaround.\n</code></pre> <p>Link a model of your choice to the Planner Agent. In our example, we use the <code>gpt-4-turbo</code> model.</p> </li> </ul> </li> </ul> <ul> <li>Engineer Agent: Create a new assistant agent named <code>Engineer</code>. No need to add any system message, you can add a description if you want, something like:<pre><code>An engineer that writes code based on the plan provided by the planner.\n</code></pre> <p>Link a model of your choice to the Planner Agent. In our example, we use the <code>gpt-4-turbo</code> model.</p> </li> </ul> <ul> <li>Executor Agent: Create a new assistant agent named <code>Executor</code>, with the following system message:<pre><code>Execute the code written by the engineer and report the result.\n</code></pre> <p>On the Code Execution tab, enable the Use Code Execution option, set the Working Directory to <code>coding</code>, and set a default timeout for the code execution to wait. We use <code>30</code>   seconds in this example, but you can increase it if needed.</p> <p>Do not link any model to the Executor Agent, this agent will not generate text, only execute code.</p> <p> </p> </li> </ul> <ul> <li>Writer Agent: Create a new assistant agent named <code>Writer</code>, with the following system message:<pre><code>Writer. Please write blogs in markdown format (with relevant titles) and put the content in pseudo ```md``` code block. You take feedback from the admin and refine your blog.\n</code></pre> <p>Link a model of your choice to the Writer Agent. In our example, we use the <code>gpt-4-turbo</code> model.</p> </li> </ul>"},{"location":"examples/6.html#add-agent-connections-and-run-the-flow","title":"Add agent connections and run the flow","text":"<p>1. Add a connection from the <code>Admin</code> agent to the <code>Manager</code> agent, to start the flow. For hte message we use a custom method:     <pre><code>def callable_message(sender, recipient, context):\n\"\"\"Return the task.\"\"\"\nimport datetime  # pylint: disable=import-outside-toplevel\n\ntoday = datetime.datetime.now().date()\nmessage = (\n    \"Write a blogpost about the stock price performance of \"\n    f\"Nvidia in the past month. Today's date is {today}\"\n)\nreturn message\n</code></pre></p> <p>2. Edit Flow: Set up the flow order to start with the \"Admin =&gt; Manager\" connection.   3. Run the flow and review the logs and the generated blog post.      </p>"},{"location":"examples/6.html#using-custom-transitions","title":"Using custom transitions","text":"<p>Since the agents in the group do not need to interact with all the other agents, we can use custom transitions to manage the flow more effectively. In this example, we will set up custom transitions to limit what agents can speak to each other.</p> <p>On the manger agent, Group Chat tab, Speakers section, we can set up the transitions between the agents. The Admin can speak to all the agents (well it's an admin, right?), the Engineer can speak to the Admin amd the Executor agent, the Executor can speak to the Admin the Engineer and the Planner, the Planner to Admin, Engineer and the Writer and the Writer to the Admin and the Planner.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Simple group chat without transitions: Planning 1.waldiez</li> <li>Group chat with transitions: Planning 2.waldiez</li> </ul>"},{"location":"examples/7.html","title":"RAG","text":""},{"location":"examples/7.html#group-chat-with-retrieval-augmented-generation","title":"Group Chat with Retrieval Augmented Generation","text":"<p>In this example, we configure a group chat environment with multiple agents, each assigned a specific role. A Boss Assistant agent utilizes Retrieval Augmented Generation (RAG) to help solve complex problems by retrieving relevant information and responding accurately. The task involves using Spark for parallel training in FLAML.</p> <p> </p>"},{"location":"examples/7.html#overview","title":"Overview","text":"<p>The workflow includes:</p> <ul> <li>Boss Assistant Agent: Assists with extra content retrieval power for solving difficult problems.</li> <li>(Group) Manager Agent: Manages the group chat environment.</li> <li>Code Reviewer Agent: Reviews the code.</li> <li>Product Manager Agent: Designs and plans the project.</li> <li>Senior Python Engineer Agent: Writes code to solve problems and answer questions.</li> </ul>"},{"location":"examples/7.html#agents-setup","title":"Agents setup","text":""},{"location":"examples/7.html#boss-assistant-agent","title":"Boss Assistant Agent","text":"<p>Drag and drop a new User Proxy agent to the canvas and configure it as follows:</p> <ul> <li>Name: Boss Assistant</li> <li>Description: Assistant with extra content retrieval power for solving difficult problems.</li> <li>Max consecutive auto reply: Set to 3.</li> <li>Agent Default Auto Reply: Reply <code>TERMINATE</code> if the task is done.</li> </ul> <p>Also check Use RAG box and configure the RAG settings as follows:</p> <p> </p>"},{"location":"examples/7.html#retrieve-config-tab","title":"Retrieve Config Tab","text":"<ul> <li>Task: Set the task type to Code.</li> <li>Docs Paths: Since the task is about using Spark for parallel training in FLAML, we use the following document path: <code>https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md</code></li> <li>Collection Name: <code>groupchat</code></li> <li>Number of Results: Set to 3.</li> </ul>"},{"location":"examples/7.html#vector-db-config","title":"Vector DB Config","text":"<ul> <li>Vector DB: Chroma</li> <li>Embedding Model: all-MiniLM-L6-v2, the default for Chroma.</li> <li>Use Persistent Storage: Checked</li> <li>Storage Path: <code>documents</code></li> </ul> <p>Note</p> <p>Feel free to experiment with different settings to optimize the retrieval process.</p>"},{"location":"examples/7.html#termination","title":"Termination","text":"<p>On the Termination tab, setup a simple keyword-based termination rule with the keyword <code>TERMINATE</code> and Keyword is the last word as the termination criterion.</p>"},{"location":"examples/7.html#model","title":"Model","text":"<p>Link a model of your choice to the Boss Assistant. In our example, we use the <code>gpt-3.5-turbo</code> model.</p>"},{"location":"examples/7.html#group-manager-agent","title":"Group Manager Agent","text":"<p>Drag and drop a new Group agent to the canvas and configure the Group chat settings as follows:</p> <ul> <li>Admin Name: <code>boss_assistant</code></li> <li>Max Rounds to <code>12</code>.</li> <li>Speakers Configuration: Set the speaker selection method to Round robin and allow speaker repetition.</li> <li>Model: Link a model of your choice to the Group Manager. In our example, we use the <code>gpt-3.5-turbo</code> model.</li> </ul>"},{"location":"examples/7.html#group-members","title":"Group Members","text":"<p>Drag and drop the following agents to the Group Manager agent:</p>"},{"location":"examples/7.html#code-reviewer-agent","title":"Code Reviewer Agent","text":"<ul> <li>System Message: You are a code reviewer. Reply <code>TERMINATE</code> at the end when everything is done.</li> <li>Add the Termination rule with the keyword <code>TERMINATE</code>.</li> <li>Link a model of your choice to the Code Reviewer agent.</li> </ul>"},{"location":"examples/7.html#product-manager-agent","title":"Product Manager Agent","text":"<ul> <li>System Message: You are a product manager. Reply <code>TERMINATE</code> at the end when everything is done.</li> <li>Add the Termination rule with the keyword <code>TERMINATE</code>.</li> <li>Link a model of your choice to the Product Manager agent.</li> </ul>"},{"location":"examples/7.html#senior-python-engineer-agent","title":"Senior Python Engineer Agent","text":"<ul> <li>System Message: You are a senior python engineer, you provide python code to answer questions. Reply <code>TERMINATE</code> in the end when everything is done.</li> <li>Add the Termination rule with the keyword <code>TERMINATE</code>.</li> <li>Link a model of your choice to the Senior Python Engineer agent.</li> </ul>"},{"location":"examples/7.html#connections","title":"Connections","text":"<p>Add a link between the Boss Assistant and the Group Manager to start the conversation. For the message, this type we use the RAG Message Generator. It uses autogen's <code>sender.message_generator</code> method to generate the message to pass to the Group Manager.</p> <p> </p>"},{"location":"examples/7.html#workflow","title":"Workflow","text":"<p>Before running the flow, open the Edit flow modal as usual, and add the one connection we have to the flow. Run the flow using the play button and inspect the logs to monitor the conversation between the agents.</p> <p>Files used in this example:</p> <ul> <li>Flow: RAG.waldiez</li> </ul>"},{"location":"examples/8.html","title":"ReAct","text":""},{"location":"examples/8.html#react-using-tavily","title":"ReAct using Tavily","text":"<p>In this example, we configure an Assistant agent with a search tool skill to answer a question using information retrieval. The agent will utilize the search tool to gather information before responding to the user. The workflow involves setting up the agent with specific skills and linking it to the user for interaction.</p> <p> </p>"},{"location":"examples/8.html#overview","title":"Overview","text":"<p>The workflow includes:</p> <ul> <li>Assistant Agent: Uses a search tool to gather real-time information for answering user queries.</li> <li>User Proxy Agent: Acts as a bridge to initiate the interaction.</li> <li>Agent Flow: The User Proxy sends a query to the Assistant, which uses the search tool to retrieve information.</li> </ul> <p>To set up the search_tool skill in Tavily, follow these steps before configuring the agents.</p>"},{"location":"examples/8.html#create-the-search-tool-skill","title":"Create the Search Tool Skill","text":"<ol> <li> <p>Go to the Skills tab and click on Add Skill to create a new skill:</p> <ul> <li>Name: <code>search_tool</code></li> <li>Description: \"Search tool using Tavily AI\"</li> <li>Skill Content:<pre><code>```python\nimport os\nfrom typing import Annotated\n\n\ndef search_tool(query: Annotated[str, \"The search query\"]) -&gt; Annotated[str, \"The search results\"]:\n    \"\"\"Search tool using Tavily AI.\"\"\"\n\n    from tavily import TavilyClient\n\n    tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n    return tavily.get_search_context(query=query, search_depth=\"advanced\")\n```\n</code></pre> </li> </ul> <ul> <li> <p>Environment Variables: Add the necessary environment variable for the Tavily API key.</p> <ul> <li>Key: <code>TAVILY_API_KEY</code></li> <li>Value: Enter your Tavily API key. You can get one on the Tavily website.</li> </ul> <p> </p> </li> </ul> </li> </ol>"},{"location":"examples/8.html#set-up-the-user-proxy","title":"Set up the User Proxy","text":"<ul> <li>Drag and Drop a new User Proxy agent onto the canvas.</li> <li>Configure the User Proxy agent:<ul> <li>No additional models or skills are required for the User Proxy.</li> </ul> </li> </ul>"},{"location":"examples/8.html#set-up-the-assistant-agent","title":"Set up the Assistant Agent","text":"<ul> <li>Drag and Drop an Assistant agent onto the canvas.</li> <li>Configure the Assistant agent:<ul> <li>System Message: \"Only use the tools you have been provided with. Reply TERMINATE at the end when the task is done.\"</li> </ul> </li> <li>Assign the Model:    Link a model of your choice to the User Proxy agent. In this example, we use the <code>claude-3-5-sonnet-20240620</code> model.</li> <li>Add Skills:<ul> <li>Go to the Skills tab and select <code>search_tool</code>.</li> <li>Set the Executor as User to allow manual control over the search process.</li> </ul> </li> </ul>"},{"location":"examples/8.html#establish-connections","title":"Establish Connections","text":"<ul> <li>Link the User Proxy agent to the Assistant agent by dragging a line between them.</li> <li>For the message, we use this custom method:<pre><code>def callable_message(sender, recipient, context):\n    \"\"\"Complete the message function\"\"\"\n    ReAct_prompt = \"\"\"\nAnswer the following questions as best you can. You have access to tools provided.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take\nAction Input: the input to the action\nObservation: the result of the action\n... (this process can repeat multiple times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\nQuestion: {input}\n\"\"\"\n    return ReAct_prompt.format(input=context[\"question\"])\n</code></pre> </li> </ul> <ul> <li>Add to the message context:<ul> <li>Key: <code>question</code></li> <li>Value: <code>What is the result of super bowl 2024?</code></li> </ul> </li> </ul>"},{"location":"examples/8.html#step-4-execute-and-monitor","title":"Step 4: Execute and Monitor","text":"<ol> <li>Run the flow by pressing the play button.</li> <li>In the logs section, observe how the Assistant uses the search tool to retrieve relevant information and respond to the query.</li> </ol> <p>Warning</p> <p>When running the flow for the first time, you might get an error saying <code>Please install anthropic to use anthropic</code>. Even though the library is installed (<code>ag2[anthropic]</code>), you might need to restart the kernel to resolve the issue.</p> <p>Note</p> <p>Once the flow starts, you might be prompt before running the search tool. You can just press Enter on the prompt to continue the flow.</p> <p> </p> <p>Files used in this example:</p> <ul> <li>Flow: ReAct.waldiez</li> <li>Skill: search_tool.waldiezSkill</li> </ul>"},{"location":"static/On-boarding.html","title":"On-boarding","text":"In\u00a0[\u00a0]: Copied! <pre>!{sys.executable} -m pip install -q ag2==0.3.2 ag2[anthropic]==0.3.2\n</pre> !{sys.executable} -m pip install -q ag2==0.3.2 ag2[anthropic]==0.3.2 In\u00a0[\u00a0]: Copied! <pre># pylint: disable=line-too-long,unknown-option-value,unused-argument,unused-import,invalid-name,import-error,inconsistent-quotes,missing-function-docstring,missing-param-doc,missing-return-doc\nimport csv\nimport os\nimport sqlite3\n</pre> # pylint: disable=line-too-long,unknown-option-value,unused-argument,unused-import,invalid-name,import-error,inconsistent-quotes,missing-function-docstring,missing-param-doc,missing-return-doc import csv import os import sqlite3 In\u00a0[\u00a0]: Copied! <pre>from typing import Any, Callable, Dict, List, Optional, Tuple, Union  # noqa\n</pre> from typing import Any, Callable, Dict, List, Optional, Tuple, Union  # noqa In\u00a0[\u00a0]: Copied! <pre>from autogen import (\n    AssistantAgent,\n    UserProxyAgent,\n    initiate_chats,\n    runtime_logging,\n)\n</pre> from autogen import (     AssistantAgent,     UserProxyAgent,     initiate_chats,     runtime_logging, ) In\u00a0[\u00a0]: Copied! <pre>from waldiez_api_keys import get_model_api_key\n</pre> from waldiez_api_keys import get_model_api_key In\u00a0[\u00a0]: Copied! <pre>gpt_3_5_turbo_llm_config = {\n    \"config_list\": [\n        {\n            \"model\": \"gpt-3.5-turbo\",\n            \"temperature\": 0.5,\n            \"api_type\": \"openai\",\n            \"api_key\": get_model_api_key(\"gpt_3_5_turbo\"),\n        }\n    ]\n}\nclaude_3_5_sonnet_20240620_llm_config = {\n    \"config_list\": [\n        {\n            \"model\": \"claude-3-5-sonnet-20240620\",\n            \"temperature\": 0.5,\n            \"api_type\": \"anthropic\",\n            \"api_key\": get_model_api_key(\"claude_3_5_sonnet_20240620\"),\n        }\n    ]\n}\n</pre> gpt_3_5_turbo_llm_config = {     \"config_list\": [         {             \"model\": \"gpt-3.5-turbo\",             \"temperature\": 0.5,             \"api_type\": \"openai\",             \"api_key\": get_model_api_key(\"gpt_3_5_turbo\"),         }     ] } claude_3_5_sonnet_20240620_llm_config = {     \"config_list\": [         {             \"model\": \"claude-3-5-sonnet-20240620\",             \"temperature\": 0.5,             \"api_type\": \"anthropic\",             \"api_key\": get_model_api_key(\"claude_3_5_sonnet_20240620\"),         }     ] } In\u00a0[\u00a0]: Copied! <pre>customer_proxy = UserProxyAgent(\n    name=\"customer_proxy\",\n    description=\"A user proxy agent\",\n    llm_config=False,\n    human_input_mode=\"ALWAYS\",\n    max_consecutive_auto_reply=None,\n    default_auto_reply=None,\n    code_execution_config=False,\n    is_termination_msg=None,\n)\npersonal_information_agent = AssistantAgent(\n    name=\"personal_information_agent\",\n    description=\"On-boarding Personal information agent\",\n    llm_config=claude_3_5_sonnet_20240620_llm_config,\n    system_message=\"You are a helpful customer on-boarding agent, you are here to help new customers get started with our product. Your job is to gather customer's name and location. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\\n\",\n    human_input_mode=\"NEVER\",\n    max_consecutive_auto_reply=None,\n    default_auto_reply=None,\n    code_execution_config=False,\n    is_termination_msg=lambda x: any(\n        x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)\n        for keyword in [\"TERMINATE\"]\n    ),\n)\ntopic_preference_agent = AssistantAgent(\n    name=\"topic_preference_agent\",\n    description=\"On-boarding Topic Preference Agent\",\n    llm_config=claude_3_5_sonnet_20240620_llm_config,\n    system_message=\"You are a helpful customer topic preference agent, you are here to help new customers get started with our product. Your job is to gather customer's topic of interest. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\\n\",\n    human_input_mode=\"NEVER\",\n    max_consecutive_auto_reply=None,\n    default_auto_reply=None,\n    code_execution_config=False,\n    is_termination_msg=lambda x: any(\n        x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)\n        for keyword in [\"TERMINATE\"]\n    ),\n)\ncustomer_engagement_agent = AssistantAgent(\n    name=\"customer_engagement_agent\",\n    description=\"On-boarding Customer Engagement Agent\",\n    llm_config=gpt_3_5_turbo_llm_config,\n    system_message=\"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\",\n    human_input_mode=\"NEVER\",\n    max_consecutive_auto_reply=None,\n    default_auto_reply=None,\n    code_execution_config=False,\n    is_termination_msg=lambda x: any(\n        x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)\n        for keyword in [\"TERMINATE\"]\n    ),\n)\n</pre> customer_proxy = UserProxyAgent(     name=\"customer_proxy\",     description=\"A user proxy agent\",     llm_config=False,     human_input_mode=\"ALWAYS\",     max_consecutive_auto_reply=None,     default_auto_reply=None,     code_execution_config=False,     is_termination_msg=None, ) personal_information_agent = AssistantAgent(     name=\"personal_information_agent\",     description=\"On-boarding Personal information agent\",     llm_config=claude_3_5_sonnet_20240620_llm_config,     system_message=\"You are a helpful customer on-boarding agent, you are here to help new customers get started with our product. Your job is to gather customer's name and location. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\\n\",     human_input_mode=\"NEVER\",     max_consecutive_auto_reply=None,     default_auto_reply=None,     code_execution_config=False,     is_termination_msg=lambda x: any(         x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)         for keyword in [\"TERMINATE\"]     ), ) topic_preference_agent = AssistantAgent(     name=\"topic_preference_agent\",     description=\"On-boarding Topic Preference Agent\",     llm_config=claude_3_5_sonnet_20240620_llm_config,     system_message=\"You are a helpful customer topic preference agent, you are here to help new customers get started with our product. Your job is to gather customer's topic of interest. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\\n\",     human_input_mode=\"NEVER\",     max_consecutive_auto_reply=None,     default_auto_reply=None,     code_execution_config=False,     is_termination_msg=lambda x: any(         x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)         for keyword in [\"TERMINATE\"]     ), ) customer_engagement_agent = AssistantAgent(     name=\"customer_engagement_agent\",     description=\"On-boarding Customer Engagement Agent\",     llm_config=gpt_3_5_turbo_llm_config,     system_message=\"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\",     human_input_mode=\"NEVER\",     max_consecutive_auto_reply=None,     default_auto_reply=None,     code_execution_config=False,     is_termination_msg=lambda x: any(         x.get(\"content\", \"\") and x.get(\"content\", \"\").endswith(keyword)         for keyword in [\"TERMINATE\"]     ), ) In\u00a0[\u00a0]: Copied! <pre>def sqlite_to_csv(dbname: str, table: str, csv_file: str) -&gt; None:\n    \"\"\"Convert a sqlite table to a csv file.\n\n    Parameters\n    ----------\n    dbname : str\n        The sqlite database name.\n    table : str\n        The table name.\n    csv_file : str\n        The csv file name.\n    \"\"\"\n    conn = sqlite3.connect(dbname)\n    query = f\"SELECT * FROM {table}\"  # nosec\n    try:\n        cursor = conn.execute(query)\n    except sqlite3.OperationalError:\n        conn.close()\n        return\n    rows = cursor.fetchall()\n    column_names = [description[0] for description in cursor.description]\n    data = [dict(zip(column_names, row)) for row in rows]\n    conn.close()\n    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n        _csv_writer = csv.DictWriter(file, fieldnames=column_names)\n        _csv_writer.writeheader()\n        _csv_writer.writerows(data)\n</pre> def sqlite_to_csv(dbname: str, table: str, csv_file: str) -&gt; None:     \"\"\"Convert a sqlite table to a csv file.      Parameters     ----------     dbname : str         The sqlite database name.     table : str         The table name.     csv_file : str         The csv file name.     \"\"\"     conn = sqlite3.connect(dbname)     query = f\"SELECT * FROM {table}\"  # nosec     try:         cursor = conn.execute(query)     except sqlite3.OperationalError:         conn.close()         return     rows = cursor.fetchall()     column_names = [description[0] for description in cursor.description]     data = [dict(zip(column_names, row)) for row in rows]     conn.close()     with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:         _csv_writer = csv.DictWriter(file, fieldnames=column_names)         _csv_writer.writeheader()         _csv_writer.writerows(data) In\u00a0[\u00a0]: Copied! <pre>runtime_logging.start(\n    logger_type=\"sqlite\",\n    config={\"dbname\": \"flow.db\"},\n)\n</pre> runtime_logging.start(     logger_type=\"sqlite\",     config={\"dbname\": \"flow.db\"}, ) In\u00a0[\u00a0]: Copied! <pre>initiate_chats(\n    [\n        {\n            \"sender\": personal_information_agent,\n            \"recipient\": customer_proxy,\n            \"summary_method\": \"reflection_with_llm\",\n            \"summary_args\": {\n                \"summary_prompt\": \"Return the customer information into as JSON object only: {'name': '', 'location': ''}\",\n                \"summary_role\": \"user\",\n            },\n            \"max_turns\": 1,\n            \"clear_history\": True,\n            \"message\": \"Hello, I'm here to help you get started with our product. Could you tell me your name and location?\",\n        },\n        {\n            \"sender\": topic_preference_agent,\n            \"recipient\": customer_proxy,\n            \"summary_method\": \"reflection_with_llm\",\n            \"summary_args\": {\n                \"summary_prompt\": \"Return the customer information into as JSON object only: {'topic_of_interest': ''}\",\n                \"summary_role\": \"user\",\n            },\n            \"max_turns\": 1,\n            \"clear_history\": True,\n            \"message\": \"Great! Could you tell me what topics you are interested in reading about?\",\n        },\n        {\n            \"sender\": customer_proxy,\n            \"recipient\": customer_engagement_agent,\n            \"summary_method\": \"reflection_with_llm\",\n            \"summary_args\": {\"summary_role\": \"user\"},\n            \"max_turns\": 1,\n            \"clear_history\": True,\n            \"message\": \"Let's find something fun to read.\",\n        },\n    ]\n)\nruntime_logging.stop()\n</pre> initiate_chats(     [         {             \"sender\": personal_information_agent,             \"recipient\": customer_proxy,             \"summary_method\": \"reflection_with_llm\",             \"summary_args\": {                 \"summary_prompt\": \"Return the customer information into as JSON object only: {'name': '', 'location': ''}\",                 \"summary_role\": \"user\",             },             \"max_turns\": 1,             \"clear_history\": True,             \"message\": \"Hello, I'm here to help you get started with our product. Could you tell me your name and location?\",         },         {             \"sender\": topic_preference_agent,             \"recipient\": customer_proxy,             \"summary_method\": \"reflection_with_llm\",             \"summary_args\": {                 \"summary_prompt\": \"Return the customer information into as JSON object only: {'topic_of_interest': ''}\",                 \"summary_role\": \"user\",             },             \"max_turns\": 1,             \"clear_history\": True,             \"message\": \"Great! Could you tell me what topics you are interested in reading about?\",         },         {             \"sender\": customer_proxy,             \"recipient\": customer_engagement_agent,             \"summary_method\": \"reflection_with_llm\",             \"summary_args\": {\"summary_role\": \"user\"},             \"max_turns\": 1,             \"clear_history\": True,             \"message\": \"Let's find something fun to read.\",         },     ] ) runtime_logging.stop() In\u00a0[\u00a0]: Copied! <pre>if not os.path.exists(\"logs\"):\n    os.makedirs(\"logs\")\nfor table in [\n    \"chat_completions\",\n    \"agents\",\n    \"oai_wrappers\",\n    \"oai_clients\",\n    \"version\",\n    \"events\",\n    \"function_calls\",\n]:\n    dest = os.path.join(\"logs\", f\"{table}.csv\")\n    sqlite_to_csv(\"flow.db\", table, dest)\n</pre> if not os.path.exists(\"logs\"):     os.makedirs(\"logs\") for table in [     \"chat_completions\",     \"agents\",     \"oai_wrappers\",     \"oai_clients\",     \"version\",     \"events\",     \"function_calls\", ]:     dest = os.path.join(\"logs\", f\"{table}.csv\")     sqlite_to_csv(\"flow.db\", table, dest)"},{"location":"static/On-boarding.html#on-boarding","title":"On-boarding\u00b6","text":""},{"location":"static/On-boarding.html#dependencies","title":"Dependencies\u00b6","text":""},{"location":"static/On-boarding.html#models","title":"Models\u00b6","text":""},{"location":"static/On-boarding.html#agents","title":"Agents\u00b6","text":""},{"location":"static/On-boarding.html#run-the-flow","title":"Run the flow\u00b6","text":""},{"location":"usage/index.html","title":"Getting Started","text":""},{"location":"usage/index.html#getting-started-with-waldiez","title":"\ud83d\ude80 Getting Started with Waldiez","text":"<p>You can use Waldiez in one of the following ways \u2014 pick the one that works best for you:</p> <ol> <li>\ud83c\udf10 Use the Playground \u2013 no installation required</li> <li>\ud83d\udc0d Install from PyPI \u2013 for full control and customization</li> <li>\ud83d\udc33 Use Docker \u2013 no setup, great for reproducibility</li> <li>\ud83d\udce6 Use the JupyterLab extension \u2013 for interactive notebooks</li> <li>\ud83d\udda5\ufe0f Use the Visual Studio Code extension \u2013 for a familiar IDE experience</li> <li>\ud83c\udfac Use Waldiez Studio \u2013 for a FastAPI-based web UI</li> </ol>"},{"location":"usage/index.html#1-use-the-playground-no-installation-required","title":"\ud83c\udf10 1. Use the Playground (No Installation Required)","text":"<p>You can visit the Playground at: https://waldiez.github.io</p> <p>You can:</p> <ul> <li>\ud83e\udde9 Design and edit Waldiez flows visually</li> <li>\ud83d\udd17 Share flows with others</li> <li>\u2705 Test layout and logic before running locally</li> </ul> <p>Note</p> <p>This is great for quick mockups, or early-stage exploration.</p> <p>Warning</p> <p>The Playground is read-only:</p> <ul> <li>You cannot run or export flows from the Playground.</li> <li>To convert flows to Python code or run them, use the PyPI or Docker options below.</li> </ul>"},{"location":"usage/index.html#2-install-from-pypi-recommended-for-full-functionality","title":"\ud83d\udc0d 2. Install from PyPI (Recommended for Full Functionality)","text":"<p>If you want to create, convert, and run Waldiez flows locally \u2014 with full flexibility \u2014 install Waldiez using pip.</p> <p>This option gives you:</p> <ul> <li>\u2705 Full access to the Python API and CLI  </li> <li>\ud83e\uddea Integration with JupyterLab and Waldiez Studio  </li> <li>\ud83d\udda5\ufe0f Local development with VS Code</li> </ul>"},{"location":"usage/index.html#basic-installation","title":"\ud83d\udce6 Basic Installation","text":""},{"location":"usage/index.html#optional-but-highly-recommended-create-and-activate-a-virtual-environment","title":"(Optional but highly recommended) Create and activate a virtual environment","text":"<pre><code>python3 -m venv .venv\nsource .venv/bin/activate  # or .venv\\Scripts\\Activate.ps1 on Windows\n# Upgrade pip (optional)\npython -m pip install --upgrade pip\n# Install the core Waldiez package\npip install waldiez\n</code></pre>"},{"location":"usage/index.html#optional-extras","title":"\u2795 Optional Extras","text":"<p>Install with extras depending on how you want to work:</p> <pre><code># JupyterLab integration\npip install waldiez[jupyter]  # or pip install waldiez-jupyter\n\n# Waldiez Studio (FastAPI-based web UI)\npip install waldiez[studio]  # or pip install waldiez-studio\n\n# Both\npip install waldiez[studio,jupyter]\n</code></pre> <p>Note</p> <p>These extras enable additional commands like <code>waldiez lab</code> (for JupyterLab) and <code>waldiez studio</code>.</p> <p>\ud83e\uddea Requirements:</p> <ul> <li>Python &gt;= 3.10, &lt; 3.13</li> <li>Optional: Docker/Podman if using containers later</li> </ul>"},{"location":"usage/index.html#3-use-docker-no-setup-required","title":"\ud83d\udc33 3. Use Docker (No Setup Required)","text":"<p>If you don\u2019t want to install Python or manage dependencies, you can use Waldiez directly from prebuilt container images.</p> <p>This option gives you:</p> <ul> <li>\u2705 Full functionality without installing anything</li> <li>\ud83d\udce6 Easy integration in CI, testing, or isolated dev environments</li> <li>\ud83d\udd01 Reproducible setup across teams</li> </ul> <p>Note</p> <p>\ud83d\udce6 Available Images:</p> <ul> <li><code>waldiez/waldiez</code> \u2014 CLI-only: convert and run flows</li> <li><code>waldiez/jupyter</code> \u2014 JupyterLab server with Waldiez extension</li> <li><code>waldiez/studio</code> \u2014 FastAPI web UI for local flow editing and running</li> </ul>"},{"location":"usage/index.html#windows-powershell-with-docker-or-podman-desktop","title":"\ud83e\ude9f Windows (PowerShell with Docker or Podman Desktop)","text":"<pre><code>$flow = \"C:\\Users\\YourName\\Documents\\flow.waldiez\"\n$output = \"C:\\Users\\YourName\\Documents\\waldiez_output\"\n\n# Convert a flow to Python\ndocker run --rm `\n  -v \"$flow:/flow.waldiez\" `\n  -v \"$output:/output\" `\n  waldiez/waldiez convert --file /flow.waldiez --output /output/flow.py\n\n# Convert and run it\ndocker run --rm `\n  -v \"$flow:/flow.waldiez\" `\n  -v \"$output:/output\" `\n  waldiez/waldiez run --file /flow.waldiez --output /output/output.py\n</code></pre> <p>Note</p> <p>If using Hyper-V mode, make sure your files are in a shared folder Docker Desktop has access to. More info: https://docs.docker.com/desktop/settings/windows/#file-sharing</p>"},{"location":"usage/index.html#linuxmacoswsl-docker-or-podman","title":"\ud83d\udc27 Linux/macOS/WSL (Docker or Podman)","text":"<pre><code># Convert a flow to a Python script\ndocker run --rm \\\n  -v $(pwd)/flow.waldiez:/flow.waldiez \\\n  -v $(pwd)/output:/output \\\n  waldiez/waldiez convert --file /flow.waldiez --output /output/flow.py\n\n# Convert to a Jupyter Notebook instead\ndocker run --rm \\\n  -v $(pwd)/flow.waldiez:/flow.waldiez \\\n  -v $(pwd)/output:/output \\\n  waldiez/waldiez convert --file /flow.waldiez --output /output/flow.ipynb\n\n# Convert and immediately run it\ndocker run --rm -it \\\n  -v $(pwd)/flow.waldiez:/flow.waldiez \\\n  -v $(pwd)/output:/output \\\n  waldiez/waldiez run --file /flow.waldiez --output /output/output.py\n</code></pre> <p>Note</p> <p>\ud83d\udcdd Tips:</p> <ul> <li>Try using absolute paths (or ${PWD}) in all <code>-v</code> volume mounts</li> <li>Avoid spaces or special characters in file paths</li> <li>The <code>.waldiez</code> file should be a valid flow you\u2019ve created in the Playground or elsewhere</li> <li> <p>If you\u2019re using Linux with Podman and/or SELinux, you might encounter permission errors, so you can try adding the following flags:</p> <p><code>--userns=keep-id</code> and <code>--security-opt label=disable</code> Example:</p> <pre><code>podman run \\\n    --rm \\\n    -it \\\n    -v $(pwd)/flow.waldiez:/flow.waldiez \\\n    -v $(pwd)/output:/output \\\n    --userns=keep-id \\\n    --security-opt label=disable \\\n    waldiez/waldiez convert --file /flow.waldiez --output /output/flow.py\n</code></pre> </li> </ul> <ul> <li>\ud83d\udcac If you run into any issues, feel free to open an issue on Github. We\u2019re happy to help!</li> </ul>"},{"location":"usage/index.html#4-use-the-jupyterlab-extension-for-interactive-notebooks","title":"\ud83d\udce6 4. Use the JupyterLab Extension (for Interactive Notebooks)","text":"<p>If you're already working in JupyterLab or prefer a notebook-based environment, you can use the official Waldiez extension.</p> <p>This gives you:</p> <ul> <li>\ud83d\udda5\ufe0f A visual flow editor directly inside JupyterLab</li> <li>\ud83d\udce4 Export flows to <code>.py</code> or <code>.ipynb</code></li> <li>\u25b6\ufe0f Run flows from within the notebook environment</li> </ul>"},{"location":"usage/index.html#install-with-jupyter-support","title":"\ud83d\ude80 Install with Jupyter support","text":"<p>If you installed Waldiez from PyPI, add the <code>[jupyter]</code> extra:</p> <pre><code># Option 1: Fresh install\npip install waldiez[jupyter]\n\n# Option 2: Add it to an existing install\npip install waldiez-jupyter\n</code></pre> <p>If you\u2019re using the <code>waldiez/jupyter</code> Docker image, the Waldiez extension is already preinstalled. To launch it, run:</p> <pre><code>docker run -it -p 8888:8888 -v ${PWD}/notebooks:/home/user/notebooks waldiez/jupyter\n</code></pre> <p>This will start a JupyterLab server and mount the <code>notebooks</code> directory from your host machine to the container. You can then open your browser at <code>http://localhost:8888</code> and start using Waldiez.</p> <p> </p>"},{"location":"usage/index.html#launch-the-waldiez-ui-inside-jupyterlab","title":"\u25b6\ufe0f Launch the Waldiez UI inside JupyterLab","text":"<p>Once installed, you can either:</p> <pre><code># Use the CLI to open JupyterLab with the extension:\nwaldiez lab\n\n# Or just launch JupyterLab normally:\njupyter lab\n</code></pre>"},{"location":"usage/index.html#extension-not-loading","title":"\u2753 Extension not loading?","text":"<p>Make sure you're running JupyterLab from the same environment where Waldiez is installed. If needed, you can reinstall or enable the extension manually:</p> <pre><code>jupyter labextension install waldiez\n# can also check the currently installed and enabled extensions with:\njupyter labextension list\n</code></pre> <p>Note</p> <p>You can also run Waldiez flows inside notebooks using the Python API:</p> <pre><code>from waldiez import WaldiezRunner\n\n# Load your flow from a file\nrunner = WaldiezRunner.load(\"flow.waldiez\")\n\n# Run it and write the output to a script\nrunner.run(output_path=\"output.py\")\n</code></pre>"},{"location":"usage/index.html#5-use-the-visual-studio-code-extension-familiar-ide-experience","title":"\ud83d\udda5\ufe0f 5. Use the Visual Studio Code Extension (Familiar IDE Experience)","text":"<p>If you\u2019re a VS Code user, you can work with Waldiez flows right inside your IDE using the official extension.</p> <p>This gives you:</p> <ul> <li>\ud83e\udde9 A drag-and-drop flow editor inside VS Code</li> <li>\ud83d\udcc2 Open <code>.waldiez</code> files directly</li> <li>\ud83d\udcbe Save, edit, and share flows as files</li> <li>Convert and run flows if a valid python interpreter exists.</li> </ul>"},{"location":"usage/index.html#install-the-extension","title":"\ud83d\udce5 Install the Extension","text":"<p>You can install the extension directly from the VS Code Marketplace:</p> <ol> <li>Open the Extensions panel (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code> on MacOS)</li> <li>Search for: <code>Waldiez</code> and install it</li> </ol> <p>Marketplace link: \ud83d\udd17 https://marketplace.visualstudio.com/items?itemName=Waldiez.waldiez-vscode</p> <p>Source code repo: \ud83d\udd27 https://github.com/waldiez/vscode</p>"},{"location":"usage/index.html#6-use-waldiez-studio-fastapi-based-web-ui","title":"\ud83c\udfac 6. Use Waldiez Studio (FastAPI-based Web UI)","text":"<p>Waldiez Studio is a lightweight local web application that allows you to:</p> <ul> <li>\ud83e\udde9 Create and edit flows using a visual UI</li> <li>\u25b6\ufe0f Run flows and see output directly in the browser</li> <li>\ud83d\udce4 Export flows to Python or Jupyter formats</li> <li>\ud83d\udcbb Integrate with other tools via REST API</li> </ul>"},{"location":"usage/index.html#installing-waldiez-studio","title":"\ud83d\ude80 Installing Waldiez Studio","text":"<p>If you're using PyPI, install the <code>[studio]</code> extra:</p> <pre><code>pip install waldiez[studio]\n# or\npip install waldiez-studio\n</code></pre> <p>If you\u2019re using Docker, pull the waldiez/studio image:</p> <pre><code>docker pull waldiez/studio\n</code></pre>"},{"location":"usage/index.html#running-waldiez-studio","title":"\ud83d\ude80 Running Waldiez Studio","text":"<p>You can run Waldiez Studio using the command line:</p> <pre><code>waldiez studio --help\n\n# example output (from typer \u2764\ufe0f):\n\n# Usage: waldiez studio [OPTIONS]\n\n# --host                TEXT        The host to run the server on [default: localhost]\n# --port                INTEGER     The port to run the server on [default: 8000]\n# --reload --no-reload              Reload the server on file changes [default: no-reload]\n# --log-level\n#                      [CRITICAL|ERROR|WARNING|INFO|DEBUG]  The log level [default: INFO]\n# --domain-name         TEXT        [default: localhost]\n# --trusted-hosts       TEXT        [default: []]\n# --trusted-origins     TEXT        [default: []]]\n# --force-ssl --no-force-ssl        Force SSL [default: no-force-ssl]\n# --version                         Show the version\n# --help -h                         Show this message and exit.\n</code></pre> <p>A typical usage would be:</p> <pre><code>waldiez studio --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"usage/index.html#advanced-usage","title":"\ud83e\uddea Advanced Usage","text":""},{"location":"usage/index.html#using-the-python-api","title":"\ud83d\udc0d Using the Python API","text":"<p>You can load, convert, and run <code>.waldiez</code> flows directly in Python.</p>"},{"location":"usage/index.html#export-a-flow","title":"Export a flow","text":"<pre><code>from waldiez import WaldiezExporter\n\nflow_path = \"/path/to/flow.waldiez\"\noutput_path = \"/path/to/output.py\"  # or .ipynb\n\nexporter = WaldiezExporter.load(flow_path)\nexporter.export(output_path)\n</code></pre>"},{"location":"usage/index.html#run-a-flow","title":"Run a flow","text":"<pre><code>from waldiez import WaldiezRunner\nfrom waldiez import WaldiezRunner\n\nflow_path = \"/path/to/flow.waldiez\"\noutput_path = \"/path/to/output.py\"\n\nrunner = WaldiezRunner.load(flow_path)\nrunner.run(output_path=output_path)\n</code></pre> <p>\ud83e\uddf0 Using the Command Line</p> <p>Waldiez also includes a CLI for converting and running flows:</p> <pre><code># Convert a .waldiez flow to a Python script or Jupyter notebook\nwaldiez convert --file /path/to/flow.waldiez --output /path/to/output.py\n\n# Convert and run (with optional --force if output exists)\nwaldiez run --file /path/to/flow.waldiez --output /path/to/output.py --force\n</code></pre> <p>Note</p> <p>\ud83d\udca1 Use <code>waldiez --help</code>, <code>waldiez convert --help</code> or <code>waldiez run --help</code> to explore more CLI options.</p> <p>\u27a1\ufe0f That's it! Now that you're set up, learn how to use Waldiez \u2192</p> <p> </p>"},{"location":"usage/agents.html","title":"Agents","text":"<p>In the agents view, you can design and organize agent workflows by connecting nodes representing different components in the process.</p> <ul> <li>Adding Agents:<ul> <li>On the left sidebar, you'll find options such as \"User Proxy,\" \"Assistant,\" and \"Group Manager.\" Drag and drop any of these to the canvas to start building your workflow.</li> </ul> </li> </ul> <ul> <li>Connecting Nodes:<ul> <li>Connect nodes by dragging lines from one node to another. This is used to create the information flow between agents.</li> </ul> </li> </ul> <ul> <li>Configuring Agents:<ul> <li>Each agent has settings where you can specify the model, add a system message, and set other properties.</li> <li>Double-clicking an agent allows you to edit its properties, such as setting the agent's name, linking models and skills to it, and defining the agent's behavior.</li> </ul> </li> </ul> <p> </p>"},{"location":"usage/agents.html#user-proxy-agent-assistant-agent","title":"User Proxy Agent, Assistant Agent","text":"<p>The assistant agent is a conversational agent that can interact with users and execute code. You can configure the assistant's behavior, termination settings, code execution settings, and model configuration. The user proxy agent acts as an intermediary between the user and the assistant. The settings for these agents are similar, with some differences in the default configurations.</p> <p> </p>"},{"location":"usage/agents.html#general-settings","title":"General Settings","text":"<p>This section allows you to configure the general behavior of the assistant agent.</p> <ul> <li>Human Input Mode: Select how often the agent should ask for human input after sending a message.<ul> <li>Always: Prompts for human input every time. This is the default setting for a user proxy agent.</li> <li>Terminate: Only prompts if a termination message is received or after reaching a maximum number of consecutive auto-replies.</li> <li>Never: Never prompts for human input unless a termination message is received. This is the default setting for an assistant agent.</li> </ul> </li> </ul> <ul> <li>Max Consecutive Auto Reply: Set the maximum number of consecutive auto-replies before pausing for human input.</li> <li>Agent Default Auto Reply: Enter the default reply message the agent will use when there\u2019s no human input.</li> </ul>"},{"location":"usage/agents.html#termination-settings","title":"Termination Settings","text":"<p>The termination settings specify the conditions under which the assistant should stop replying.</p> <ul> <li>Termination: Choose the type of termination condition (e.g., by keyword or custom method).</li> <li>Termination Criterion: Set the specific criterion (e.g., \"Keyword is found\").</li> <li>Termination Keywords: Enter the keywords that will trigger termination.</li> </ul>"},{"location":"usage/agents.html#code-execution-settings","title":"Code Execution Settings","text":"<p>If your assistant can execute code, configure these options here.</p> <ul> <li>Use Code Execution: Check this box to enable code execution capabilities.</li> <li>Working Directory: Set the directory where code will be executed.</li> <li>Last N Messages: Specify the number of previous messages to consider when executing code.</li> <li>Timeout: Set a timeout limit for code execution.</li> <li>Use Docker: Enable Docker for isolated code execution, if needed.</li> <li>Functions: Select specific functions the assistant can use.</li> </ul>"},{"location":"usage/agents.html#model-configuration","title":"Model Configuration","text":"<p>Link models to your agent in this section.</p> <ul> <li>Models linked to agent: Select the model you wish to link. Multiple models can be linked for various functionalities.</li> </ul>"},{"location":"usage/agents.html#skill-management","title":"Skill Management","text":"<p>Define specific skills for the assistant.</p> <ul> <li>Skill: Select a previously defined skill to link to the agent.</li> <li>Executor: Choose the executor responsible for running the skill.</li> <li>Current Skills: View and manage currently linked skills.</li> </ul>"},{"location":"usage/agents.html#nested-chats-configuration","title":"Nested Chats Configuration","text":"<p>When an agent is connected to another agent, you can configure the nested chat settings to create a multi-step conversation flow. This allows you to set up automated chat sequences that are triggered based on specific messages. This can be used to guide conversations through predefined paths.   </p>"},{"location":"usage/agents.html#overview","title":"Overview","text":"<ul> <li>Triggered by: Select who initiates the nested chat.<ul> <li>For example, <code>User =&gt; Assistant</code> means the user sends a message to the assistant, which then triggers the nested chat.</li> </ul> </li> </ul> <ul> <li>Agent's Reply: Check this box if the message should be sent from the assistant back to the user. If unchecked, the message will be directed to the next agent in the nested sequence.</li> </ul> <ul> <li>Messages:<ul> <li>Use this to specify the nested chat that will be triggered.</li> <li>The final message in the sequence will return to the main chat.</li> <li>If the Agent's Reply box is checked, the trigger message is sent to the assistant; otherwise, it is sent to the user.</li> </ul> </li> </ul>"},{"location":"usage/agents.html#configure-nested-chats","title":"Configure Nested Chats","text":"<ol> <li> <p>Define Trigger:</p> <ul> <li>Select the interaction pattern for triggering nested chats (e.g., <code>User =&gt; Assistant</code>).</li> <li>Click Add to include this trigger.</li> </ul> </li> <li> <p>Set Messages:</p> <ul> <li>In the Messages dropdown, select the message or nested chat sequence you wish to include.</li> <li>Check Agent's Reply if this message should be sent back to the assistant; otherwise, leave it unchecked.</li> </ul> </li> <li> <p>Add or Remove Steps:</p> <ul> <li>Use Add to include additional messages or nested chat sequences.</li> <li>Remove steps as needed to refine the flow.</li> </ul> </li> </ol> <p>Use these settings to create complex conversation flows that can help automate responses and guide users through a series of related interactions.</p> <p>Each of these sections allows you to customize the assistant's behavior and capabilities. Make sure to save changes before exiting the modal.</p>"},{"location":"usage/agents.html#group-manager-agent","title":"Group Manager Agent","text":"<p>A group manager agent is used to manage group chats and multi-agent conversations. It allows you to configure group settings, speaker selection, and transitions between speakers.</p>"},{"location":"usage/agents.html#group-chat-configuration","title":"Group Chat Configuration","text":"<p>The Group Chat configuration allows you to manage group settings, speaker selection, and transitions between speakers in a multi-agent chat environment.</p>"},{"location":"usage/agents.html#configuration","title":"Configuration","text":""},{"location":"usage/agents.html#settings","title":"Settings","text":"<ul> <li>Admin Name: Define the name of the group admin.</li> <li>Max Rounds: Set the maximum number of conversation rounds for the group.</li> <li>Enable Clear History: Check this to allow history to be cleared after each conversation.</li> <li>Send Introductions: Enable this to automatically send introductions at the beginning.</li> <li>Max Retries for Selecting Speaker: Define the maximum retries for selecting a speaker.</li> </ul>"},{"location":"usage/agents.html#speakers","title":"Speakers","text":""},{"location":"usage/agents.html#speaker-selection","title":"Speaker Selection","text":"<ul> <li>Speaker Repetition Mode: Choose how often a speaker can repeat.<ul> <li>Disabled (Use transitions): The next speaker is chosen based on transitions.</li> <li>Enabled: Allows the same speaker to repeat based on set parameters.</li> </ul> </li> </ul> <ul> <li>Speaker Selection Method: Select the method for determining the next speaker:<ul> <li>Auto: Automatically selects the next speaker.</li> <li>Manual: Allows manual selection of the next speaker.</li> <li>Random: Randomly selects the next speaker.</li> <li>Round Robin: Selects speakers in a round-robin fashion.</li> <li>Custom Method: Use a custom function to select the next speaker.</li> </ul> </li> </ul>"},{"location":"usage/agents.html#speaker-transitions","title":"Speaker Transitions","text":"<p>Set specific transitions between speakers.</p> <ol> <li>From / To: Choose which agents the transition applies to. You can select more than one agents for the \"To\" field.</li> <li>Transitions Mode: Select if transitions are Allowed or Blocked.</li> <li>Add Transition: Click Add to save the transition.</li> </ol> <p>These settings allow you to manage complex group conversations and control transitions between speakers that are members of the same group.</p>"},{"location":"usage/agents.html#rag-user-proxy-agent","title":"RAG User Proxy Agent","text":"<p>A RAG User Proxy agent is used to enable retrieval-augmented generation (RAG) for generating responses. You can configure the agent to use RAG, set up document retrieval, customize text splitting, and define advanced settings. This can be useful for creating responses based on dynamic content retrieval and custom function integration.</p> <p> </p>"},{"location":"usage/agents.html#enable-rag-and-basic-settings","title":"Enable RAG and Basic Settings","text":"<p>In the Agent tab, you can enable RAG to allow the agent to use retrieval-augmented generation for generating responses.</p> <ul> <li>Use RAG: Check this box to activate RAG for the agent.</li> <li>Name, Description, System Message: Fill out the name, description, and any system message for the agent.</li> <li>Human Input Mode: Set when the agent should request human input.</li> <li>Max Consecutive Auto Reply: Define the limit for consecutive auto-replies.</li> <li>Agent Default Auto Reply: Specify a default message if there\u2019s no human input.</li> </ul>"},{"location":"usage/agents.html#rag-configuration-retrieve-config","title":"RAG Configuration - Retrieve Config","text":"<p>In the RAG tab, configure the retrieval settings for the agent.</p> <ul> <li>Task: Select the RAG task, such as <code>code</code>, <code>qa</code>, or <code>default</code>. The task affects the system prompt used.</li> <li>Docs Paths: Specify paths to any documents you wish to include.</li> <li>Collection Name: Set the collection name (e.g., <code>autogen-docs</code>).</li> <li>Number of Results: Define the number of documents to retrieve for responses.</li> <li>Distance Threshold: Set a distance threshold for document retrieval relevance.</li> </ul>"},{"location":"usage/agents.html#rag-configuration-text-splitting","title":"RAG Configuration - Text Splitting","text":"<p>Customize text splitting settings to control how the retrieved content is processed.</p> <ul> <li>Chunk Token Size: Set the size of text chunks in tokens.</li> <li>Context Max Tokens: Define the maximum number of tokens for context.</li> <li>Chunk Mode: Choose the chunking mode (<code>Multi Lines</code>, <code>Single Line</code>, etc.).</li> <li>Must Break at Empty Line: Check this if chunks should only break at empty lines when in <code>Multi Lines</code> mode.</li> </ul>"},{"location":"usage/agents.html#rag-configuration-vector-db-config","title":"RAG Configuration - Vector DB Config","text":"<p>Set up the Vector Database for embedding and retrieval.</p> <ul> <li>Embedding Model: Choose the model for embeddings. Available models include <code>all-MiniLM-L6-v2</code>, <code>bge-small-en-v1.5</code>, etc.</li> <li>Use Persistent Storage: Enable this to store embeddings persistently.</li> <li>Connection URL: Enter the connection URL for the vector database.</li> </ul>"},{"location":"usage/agents.html#rag-configuration-custom-functions","title":"RAG Configuration - Custom Functions","text":"<p>Enable and define custom functions for embedding, token count, and text splitting.</p> <ul> <li>Use Custom Embedding Function: Check this box to enable a custom function for embeddings.</li> <li>Embedding Function: Define the Python function for custom embeddings. Refer to the code example provided to see how to structure the function.</li> </ul>"},{"location":"usage/agents.html#rag-configuration-advanced-settings","title":"RAG Configuration - Advanced Settings","text":"<p>The Advanced tab offers additional configuration options. You probably won't need to adjust these settings unless you have specific requirements.</p> <ul> <li>Customized Prompt: Specify a custom prompt for generating responses.</li> <li>Customized Answer Prefix: Add a prefix for responses generated by the agent.</li> <li>Options: Check options like <code>Update Context</code>, <code>Get or Create</code>, <code>New Docs</code>, <code>Overwrite</code>, and <code>Recursive</code> to further control document handling and context updates.</li> </ul>"},{"location":"usage/convert.html","title":"Convert","text":""},{"location":"usage/convert.html#convert-a-waldiez-flow","title":"Convert a Waldiez flow","text":"<p>Instead of directly running, you can export it as a Python script or a Jupyter notebook. You can just right click on the <code>.waldiez</code> file in the jupyter lab file browser and select <code>To python</code> or <code>To notebook</code>.</p> <p> </p> <p>Here is an example Jupyter notebook generated from a Waldiez flow: On-boarding.ipynb</p>"},{"location":"usage/flow.html","title":"Flow","text":""},{"location":"usage/flow.html#connecting-agents","title":"Connecting Agents","text":"<p>Once you have created and configured agents, you can connect them to create a flow of interactions. This flow can be as simple as a single agent responding to user inputs or as complex as multiple agents interacting with each other.</p>"},{"location":"usage/flow.html#chats","title":"Chats","text":""},{"location":"usage/flow.html#message-type-and-content","title":"Message Type and Content","text":"<p>In the Message tab, you can set the type and content of the message that will be sent from the source (e.g., Assistant) to the target (e.g., User).</p> <ul> <li>Message Type: Choose the type of message from the dropdown:<ul> <li>None: No message is sent.</li> <li>Text: Allows for sending a custom text message.</li> <li>Custom Method: Select this if you have a custom message handling method.</li> </ul> </li> </ul> <ul> <li>Message Content: If \"Text\" is selected as the type, enter the specific message you want to send here.</li> </ul>"},{"location":"usage/flow.html#carryover-option","title":"Carryover Option","text":"<p>The Carryover setting determines if the last context from a previous message should be appended to the new message.</p> <ul> <li>Carryover: Check this box to include the last carryover context in the message.<ul> <li>For example, if the carryover context includes instructions or prior context, it will be appended to the message.</li> </ul> </li> </ul> <p>Note</p> <p>Do not check Carryover if this is the first message in the flow.</p>"},{"location":"usage/flow.html#nested-chats","title":"Nested Chats","text":"<p>If the type of chat is a nested chat, you can configure the nested chat settings in the Nested Chat tab. Here, in addition to the message type and content, you can set up replies specific to nested chat interactions.</p>"},{"location":"usage/flow.html#flow-order-and-dependencies","title":"Flow Order and Dependencies","text":"<p>This guide explains how to configure and manage flows, which are sequences of actions or chats that an agent can execute.</p> <p> </p>"},{"location":"usage/flow.html#edit-flow-basic-settings","title":"Edit Flow - Basic Settings","text":"<p>In the Edit Flow tab, set up the basic details and order of chats in the flow.</p> <ul> <li>Name: Enter a name for the flow.</li> <li>Description: Provide a brief description of the flow.</li> <li>Order: Define the sequence in which chats should run when the flow initializes.<ul> <li>Add a Chat: Use the dropdown to select and add a new chat to the flow order.</li> <li>Remove a Chat: Click Remove next to a chat to delete it from the sequence.</li> <li>Reorder Chats: Use the \u2191 and \u2193 buttons to adjust the order of chats.</li> </ul> </li> </ul>"},{"location":"usage/flow.html#edit-flow-other-settings","title":"Edit Flow - Other Settings","text":"<p>In the Other tab, specify any additional requirements or tags for the flow.</p> <ul> <li>Additional Requirements: Add any Python packages that need to be installed before running the flow.<ul> <li>Example: If your flow requires the <code>pandas</code> library, type <code>pandas</code> and click + to add it to the requirements list.</li> <li>Each package listed here will be installed via <code>pip install</code> before the flow starts.</li> </ul> </li> <li>Tags: Add relevant tags to categorize the flow for easier management or searching.</li> </ul>"},{"location":"usage/models.html","title":"Models","text":""},{"location":"usage/models.html#setting-up-a-model","title":"Setting Up a Model","text":"<ul> <li>Create a new model: On the Models view, click \"Add model\" to create a new model. You can click on the gear icon, or double click the model's view to access its settings.</li> </ul> <ul> <li>Basic Tab:<ul> <li>Name: Enter a unique name for the model.</li> <li>Description: Provide a brief description of the model's purpose or functionality.</li> <li>Model Type: Select the model type (e.g., OpenAI) from the dropdown list.</li> <li>API Key: Input your API key to authenticate requests.</li> <li>Base URL: If the base URL is not one that is pre-filled, you can specify the API base URL (for OpenAI models, it\u2019s usually <code>https://api.openai.com/v1</code> but for other OpenAI compatible models, this can differ).</li> </ul> </li> </ul> <ul> <li>Advanced Tab:<ul> <li>Temperature: Adjust the temperature (a value between 0 and 1) to control the creativity of the model's output. Lower values produce more deterministic results, while higher values allow for more diverse responses.</li> <li>Top P: Set the Top P parameter to limit the selection of tokens based on cumulative probability. If you want it unset, leave it as is.</li> <li>Max Tokens: Define the maximum token count for each response (set to \"No limit\" in the example).</li> <li>Default Headers: Add any additional headers needed for API requests (optional).</li> <li>Tags: Use tags to categorize or label the model (optional but recommended).</li> </ul> </li> </ul> <ul> <li>Price Tab:<ul> <li>Prompt price per 1K tokens: Enter the price per 1,000 tokens for the model (optional).</li> <li>Completion price per 1K tokens: Enter the price per 1,000 tokens for completions (optional).</li> </ul> </li> </ul> <ul> <li>Save the Configuration:<ul> <li>After completing the setup in any of the tabs, click Save to confirm and apply the model configuration.</li> </ul> </li> </ul> <p>This setup will enable you to link this model to one or more agents for generating responses based on the model's capabilities.</p>"},{"location":"usage/run.html","title":"Running and Troubleshooting","text":""},{"location":"usage/run.html#running-a-flow","title":"Running a Flow","text":"<p>Once we have setup the models, agents, and connections in the flow, we open the Edit Flow modal to specify which connections should be used to initiate the conversation, specify any additional requirements that might be needed. Let's also give the flow a descriptive name and maybe a short description.</p> <p> </p>"},{"location":"usage/run.html#troubleshooting-errors","title":"Troubleshooting Errors","text":"<p>During the flow execution, you might encounter errors that can interrupt the conversation. Here are some common errors and solutions to help you resolve them.</p> <p>Warning</p> <p>If you are on python 3.13, and trying to use a crewAI Tool, this will probably not work, because python3.13 is not yet supported on crawAI (unless we haven't updated this page \ud83d\ude1b). Here are some links to check the compatibility:</p> <ul> <li>https://github.com/ag2ai/ag2/blob/main/pyproject.toml#L178-L180</li> <li>https://github.com/crewAIInc/crewAI/blob/main/pyproject.toml#L6</li> </ul>"},{"location":"usage/run.html#troubleshooting-common-errors","title":"Troubleshooting Common Errors","text":"<p>Note</p> <p>If an error persists, or new packages were installed, you might need to restart the kernel to apply the changes. If this does not resolve the issue, or you need further assistance, please reach out to us, we are more than happy to help!</p>"},{"location":"usage/run.html#chromadb-installation-fails-on-windows","title":"ChromaDB Installation Fails on Windows","text":"<p>Description: When installing <code>chromadb</code> on Windows, you might encounter build errors due to missing C++ build tools.</p> <ul> <li> <p>Error Message (example):</p> <p><code>text error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\"</code></p> </li> </ul> <ul> <li>Cause: Some ChromaDB dependencies require native code compilation. Windows systems need additional tools for this. Here is a related link on chroma's repository with a solution (thanks to the author): https://github.com/chroma-core/chroma/issues/189#issuecomment-1454418844</li> </ul> <ul> <li> <p>Solution:</p> <ul> <li>Install the required C++ build tools from the Microsoft website. You probably need to install a few only components (based on you windows version, see the link above if in doubt).</li> <li> <p>You can manually test the installation of <code>chromadb</code> by running the following command in your terminal:</p> <pre><code>pip install chromadb\n</code></pre> </li> </ul> <ul> <li>If the installation is successful, you can proceed with the flow. If not, check the error messages for more details.</li> </ul> </li> </ul> <p>Note</p> <p>This error could also occur with other extra dependencies that might be needed for running a flow, so keep in mind this error in case you are using other packages that require native code compilation.</p> <p> </p>"},{"location":"usage/run.html#validationerror-agent-not-connected","title":"ValidationError: Agent Not Connected","text":"<p>Description: This error occurs when an agent in the flow is not connected to any other node, causing the flow to be incomplete.</p> <ul> <li>Error Message:</li> </ul> <pre><code>  ValidationError: 1 validation error for [Flow Name]\n  Value error, Agent does not connect to any other node.\n</code></pre> <ul> <li>Solution:<ul> <li>Identify the agent mentioned in the error (e.g., <code>Planner</code>).</li> <li>Connect this agent to another node in the flow to complete the sequence.</li> <li>Re-run the flow after making the connection.</li> </ul> </li> </ul> <p> </p>"},{"location":"usage/run.html#openai-error-missing-api-key","title":"OpenAI Error: Missing API Key","text":"<p>Description: This error appears when the OpenAI API key is not set, preventing the tool from accessing OpenAI's services.</p> <ul> <li> <p>Error Message:</p> <pre><code>OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable.\n</code></pre> </li> </ul> <ul> <li>Solution:<ul> <li>Make sure you have set the API key in the model configuration.</li> <li>Restart the flow after setting the API key to ensure it is recognized.</li> </ul> </li> </ul>"},{"location":"usage/run.html#skill-or-custom-functions-related-errors","title":"Skill or custom functions related errors","text":"<p>Description: Errors related to skills or custom functions can occur due to incorrect function names, missing environment variables, or syntax errors in the code.</p> <p> </p> <p>Make sure to check the following:</p> <ul> <li>Function Name: In skills, ensure the function name in the code matches the skill name.</li> <li>Syntax Errors: Review the code for any syntax errors or typos that may cause the function to fail.</li> <li>Environment Variables: If environment variables are required, ensure they are correctly set in the skill configuration.</li> <li>Logs: Check the logs for detailed error messages that can help identify the issue.</li> </ul>"},{"location":"usage/run.html#general-debugging-tips","title":"General Debugging Tips","text":"<ul> <li>Check Connections: Ensure all nodes are connected correctly in the flow. Unconnected nodes can interrupt the flow sequence.</li> <li>Verify Configuration: Review the configuration for each agent and node. Ensure all fields are populated with valid data, especially required fields like API keys.</li> <li>Restart and Retry: After making changes to resolve errors, restart the flow to test if the issue is resolved.</li> <li>Review Logs: Check the logs for detailed error messages or warnings that can help identify the root cause of the issue.</li> </ul>"},{"location":"usage/skills.html","title":"Skills","text":""},{"location":"usage/skills.html#setting-up-a-new-skill","title":"Setting Up a new Skill","text":"<ul> <li>Create a new skill:     On the Skills view, click \"Add skill\" to create a new skill. You can click on the gear icon, or double click the skill's view to access its settings.</li> </ul> <ul> <li>Basic Information:<ul> <li>Name: Enter a unique name for the skill (e.g., <code>new_skill</code>).</li> <li>Description: Provide a brief description of the skill's purpose.</li> </ul> <p>Note</p> <p>The skill name should match the function name in the code.</p> </li> </ul> <ul> <li>Content Section:<ul> <li>This is where you define the code for your skill</li> <li>Template Code:<ul> <li>Replace the provided template code with your actual implementation.</li> <li>Ensure that the function name matches the skill's name (e.g., if the skill is named <code>new_skill</code>, the function should also be named <code>new_skill</code>).</li> </ul> </li> <li>Example:<pre><code>  \"\"\"\n  Replace this with your code.\n  Ensure the function name matches the skill name.\n  \"\"\"\n  def new_skill() -&gt; None:\n      \"\"\"Skill entry point.\"\"\"\n      # Add your logic here\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Environment Variables (Optional):<ul> <li>Add any necessary environment variables as key-value pairs to support the skill.</li> <li>Click the + button to add multiple environment variables if required.</li> </ul> </li> </ul> <ul> <li>Save the Configuration:<ul> <li>Once you have entered the skill details and code, click Save to confirm and apply the skill configuration.</li> </ul> </li> </ul> <p>This setup enables you to define and configure a new skill within your project by providing necessary code, naming conventions, and any environment variables.</p>"},{"location":"blog/category/standup-comedians.html","title":"Standup comedians","text":""},{"location":"blog/category/standup-comedians.html#standup-comedians","title":"Standup Comedians","text":""},{"location":"blog/category/sequential-chats.html","title":"Sequential chats","text":""},{"location":"blog/category/sequential-chats.html#sequential-chats","title":"Sequential chats","text":""},{"location":"blog/category/customer-onboarding.html","title":"Customer onboarding","text":""},{"location":"blog/category/customer-onboarding.html#customer-onboarding","title":"Customer onboarding","text":""}]}